# -*- coding: utf-8 -*-
"""
EIQåˆ†ææ¨¡å— - ä¸“é—¨å¤„ç†EIQåˆ†æç›¸å…³åŠŸèƒ½
EIQ (Entry, Item, Quantity) åˆ†æå‡ºå…¥åº“è®¢å•ç»“æ„å’Œç‰¹å¾
"""

import pandas as pd
import numpy as np
import streamlit as st
from typing import Dict, List, Any, Tuple, Optional
from config import ANALYSIS_DIMENSIONS

class EIQAnalyzer:
    """EIQåˆ†æå™¨"""
    
    def __init__(self, analysis_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–EIQåˆ†æå™¨
        
        Args:
            analysis_config: åˆ†æé…ç½®å­—å…¸
        """
        self.config = analysis_config or self._get_default_config()
        
    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'analysis_period': 'monthly',  # daily, weekly, monthly, quarterly
            'entry_threshold': 10,  # è®¢å•æ•°é‡é˜ˆå€¼
            'item_threshold': 5,   # å•å“æ•°é‡é˜ˆå€¼  
            'quantity_threshold': 100,  # æ•°é‡é˜ˆå€¼
            'include_charts': True,  # æ˜¯å¦ç”Ÿæˆå›¾è¡¨
            'group_small_entries': True  # æ˜¯å¦åˆå¹¶å°è®¢å•
        }
    
    def validate_data(self, df: pd.DataFrame, entry_column: str, 
                     item_column: str, quantity_column: str, 
                     date_column: Optional[str] = None) -> Tuple[bool, List[str]]:
        """
        éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
        
        Args:
            df: æ•°æ®æ¡†
            entry_column: è®¢å•åˆ—åï¼ˆEntryï¼‰
            item_column: å•†å“åˆ—åï¼ˆItemï¼‰
            quantity_column: æ•°é‡åˆ—åï¼ˆQuantityï¼‰
            date_column: æ—¥æœŸåˆ—åï¼ˆå¯é€‰ï¼‰
            
        Returns:
            tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        
        # æ£€æŸ¥æ•°æ®æ¡†æ˜¯å¦ä¸ºç©º
        if df.empty:
            errors.append("æ•°æ®æ¡†ä¸ºç©º")
            return False, errors
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = [entry_column, item_column, quantity_column]
        for col in required_columns:
            if col not in df.columns:
                errors.append(f"å¿…éœ€åˆ— '{col}' ä¸å­˜åœ¨")
        
        if date_column and date_column not in df.columns:
            errors.append(f"æ—¥æœŸåˆ— '{date_column}' ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if quantity_column in df.columns:
            try:
                qty_data = pd.to_numeric(df[quantity_column], errors='coerce')
                if qty_data.isna().all():
                    errors.append(f"æ•°é‡åˆ— '{quantity_column}' æ— æ³•è½¬æ¢ä¸ºæ•°å€¼")
                elif qty_data.isna().any():
                    na_count = qty_data.isna().sum()
                    errors.append(f"æ•°é‡åˆ— '{quantity_column}' æœ‰ {na_count} ä¸ªæ— æ•ˆå€¼")
            except Exception as e:
                errors.append(f"æ•°é‡åˆ—æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
        
        # æ£€æŸ¥æ—¥æœŸåˆ—
        if date_column and date_column in df.columns:
            try:
                pd.to_datetime(df[date_column], errors='coerce')
            except Exception as e:
                errors.append(f"æ—¥æœŸåˆ—æ•°æ®éªŒè¯å¤±è´¥: {str(e)}")
        
        return len(errors) == 0, errors
    
    def analyze_entry_patterns(self, df: pd.DataFrame, entry_column: str, 
                              item_column: str, quantity_column: str) -> Dict[str, Any]:
        """
        åˆ†æEntryï¼ˆè®¢å•ï¼‰æ¨¡å¼
        
        Args:
            df: æ•°æ®æ¡†
            entry_column: è®¢å•åˆ—å
            item_column: å•†å“åˆ—å  
            quantity_column: æ•°é‡åˆ—å
            
        Returns:
            dict: Entryåˆ†æç»“æœ
        """
        # æŒ‰è®¢å•åˆ†ç»„ç»Ÿè®¡
        entry_stats = df.groupby(entry_column).agg({
            item_column: 'nunique',  # ä¸åŒå•†å“æ•°é‡
            quantity_column: ['sum', 'mean', 'count']  # æ€»æ•°é‡ã€å¹³å‡æ•°é‡ã€è¡Œæ•°
        }).round(2)
        
        # é‡å‘½ååˆ—
        entry_stats.columns = ['å•†å“ç§ç±»æ•°', 'æ€»æ•°é‡', 'å¹³å‡æ•°é‡', 'è¡Œæ•°']
        entry_stats['è®¢å•ç¼–å·'] = entry_stats.index
        
        # è®¡ç®—è®¢å•ç‰¹å¾
        entry_stats['è®¢å•è§„æ¨¡'] = pd.cut(entry_stats['å•†å“ç§ç±»æ•°'], 
                                      bins=[0, 1, 5, 10, float('inf')], 
                                      labels=['å•å“è®¢å•', 'å°è®¢å•', 'ä¸­è®¢å•', 'å¤§è®¢å•'])
        
        entry_stats['æ•°é‡è§„æ¨¡'] = pd.cut(entry_stats['æ€»æ•°é‡'], 
                                      bins=[0, 10, 50, 200, float('inf')], 
                                      labels=['å°é‡', 'ä¸­é‡', 'å¤§é‡', 'è¶…å¤§é‡'])
        
        # è®¢å•åˆ†å¸ƒç»Ÿè®¡
        order_distribution = {
            'total_entries': len(entry_stats),
            'single_item_orders': len(entry_stats[entry_stats['å•†å“ç§ç±»æ•°'] == 1]),
            'multi_item_orders': len(entry_stats[entry_stats['å•†å“ç§ç±»æ•°'] > 1]),
            'avg_items_per_order': entry_stats['å•†å“ç§ç±»æ•°'].mean(),
            'avg_quantity_per_order': entry_stats['æ€»æ•°é‡'].mean(),
            'max_items_per_order': entry_stats['å•†å“ç§ç±»æ•°'].max(),
            'max_quantity_per_order': entry_stats['æ€»æ•°é‡'].max()
        }
        
        return {
            'entry_details': entry_stats.reset_index(drop=True),
            'entry_distribution': order_distribution
        }
    
    def analyze_item_patterns(self, df: pd.DataFrame, entry_column: str, 
                             item_column: str, quantity_column: str) -> Dict[str, Any]:
        """
        åˆ†æItemï¼ˆå•†å“ï¼‰æ¨¡å¼
        
        Args:
            df: æ•°æ®æ¡†
            entry_column: è®¢å•åˆ—å
            item_column: å•†å“åˆ—å
            quantity_column: æ•°é‡åˆ—å
            
        Returns:
            dict: Itemåˆ†æç»“æœ
        """
        # æŒ‰å•†å“åˆ†ç»„ç»Ÿè®¡
        item_stats = df.groupby(item_column).agg({
            entry_column: 'nunique',  # å‡ºç°åœ¨å¤šå°‘ä¸ªè®¢å•ä¸­
            quantity_column: ['sum', 'mean', 'count']  # æ€»æ•°é‡ã€å¹³å‡æ•°é‡ã€å‡ºç°æ¬¡æ•°
        }).round(2)
        
        # é‡å‘½ååˆ—
        item_stats.columns = ['è®¢å•é¢‘æ¬¡', 'æ€»éœ€æ±‚é‡', 'å¹³å‡éœ€æ±‚é‡', 'å‡ºç°æ¬¡æ•°']
        item_stats['å•†å“ç¼–å·'] = item_stats.index
        
        # è®¡ç®—å•†å“ç‰¹å¾
        item_stats['éœ€æ±‚é¢‘ç‡'] = pd.cut(item_stats['è®¢å•é¢‘æ¬¡'], 
                                     bins=[0, 1, 5, 20, float('inf')], 
                                     labels=['ä½é¢‘', 'ä¸­ä½é¢‘', 'ä¸­é«˜é¢‘', 'é«˜é¢‘'])
        
        item_stats['éœ€æ±‚é‡çº§'] = pd.cut(item_stats['æ€»éœ€æ±‚é‡'], 
                                     bins=[0, 10, 100, 500, float('inf')], 
                                     labels=['å°é‡', 'ä¸­é‡', 'å¤§é‡', 'è¶…å¤§é‡'])
        
        # å•†å“åˆ†å¸ƒç»Ÿè®¡  
        item_distribution = {
            'total_items': len(item_stats),
            'high_frequency_items': len(item_stats[item_stats['è®¢å•é¢‘æ¬¡'] >= 10]),
            'low_frequency_items': len(item_stats[item_stats['è®¢å•é¢‘æ¬¡'] == 1]),
            'avg_orders_per_item': item_stats['è®¢å•é¢‘æ¬¡'].mean(),
            'avg_quantity_per_item': item_stats['æ€»éœ€æ±‚é‡'].mean(),
            'top_items_quantity': item_stats['æ€»éœ€æ±‚é‡'].nlargest(10).sum()
        }
        
        return {
            'item_details': item_stats.reset_index(drop=True),
            'item_distribution': item_distribution
        }
    
    def analyze_quantity_patterns(self, df: pd.DataFrame, entry_column: str, 
                                 item_column: str, quantity_column: str) -> Dict[str, Any]:
        """
        åˆ†æQuantityï¼ˆæ•°é‡ï¼‰æ¨¡å¼
        
        Args:
            df: æ•°æ®æ¡†
            entry_column: è®¢å•åˆ—å
            item_column: å•†å“åˆ—å
            quantity_column: æ•°é‡åˆ—å
            
        Returns:
            dict: Quantityåˆ†æç»“æœ
        """
        # æ•°é‡ç»Ÿè®¡
        quantities = pd.to_numeric(df[quantity_column], errors='coerce').dropna()
        
        quantity_stats = {
            'total_quantity': quantities.sum(),
            'avg_quantity': quantities.mean(),
            'median_quantity': quantities.median(),
            'std_quantity': quantities.std(),
            'min_quantity': quantities.min(),
            'max_quantity': quantities.max(),
            'quantity_records': len(quantities)
        }
        
        # æ•°é‡åˆ†å¸ƒ
        quantity_distribution = pd.cut(quantities, 
                                     bins=[0, 1, 5, 10, 50, float('inf')], 
                                     labels=['1ä»¶', '2-5ä»¶', '6-10ä»¶', '11-50ä»¶', '50ä»¶ä»¥ä¸Š'])
        
        quantity_dist_counts = quantity_distribution.value_counts().to_dict()
        
        # æŒ‰è®¢å•å’Œå•†å“çš„æ•°é‡åˆ†æ
        entry_item_qty = df.groupby([entry_column, item_column])[quantity_column].sum().reset_index()
        entry_item_qty['æ•°é‡ç±»åˆ«'] = pd.cut(pd.to_numeric(entry_item_qty[quantity_column], errors='coerce'), 
                                        bins=[0, 1, 5, 20, float('inf')], 
                                        labels=['å•ä»¶', 'å°‘é‡', 'ä¸­é‡', 'å¤§é‡'])
        
        return {
            'quantity_statistics': quantity_stats,
            'quantity_distribution': quantity_dist_counts,
            'entry_item_quantities': entry_item_qty
        }
    
    def generate_eiq_summary(self, entry_analysis: Dict[str, Any], 
                           item_analysis: Dict[str, Any], 
                           quantity_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”ŸæˆEIQç»¼åˆåˆ†ææ‘˜è¦
        
        Args:
            entry_analysis: Entryåˆ†æç»“æœ
            item_analysis: Itemåˆ†æç»“æœ  
            quantity_analysis: Quantityåˆ†æç»“æœ
            
        Returns:
            dict: EIQç»¼åˆæ‘˜è¦
        """
        entry_dist = entry_analysis['entry_distribution']
        item_dist = item_analysis['item_distribution']
        qty_stats = quantity_analysis['quantity_statistics']
        
        # è®¡ç®—å…³é”®æŒ‡æ ‡
        single_item_ratio = (entry_dist['single_item_orders'] / entry_dist['total_entries'] * 100) if entry_dist['total_entries'] > 0 else 0
        high_freq_item_ratio = (item_dist['high_frequency_items'] / item_dist['total_items'] * 100) if item_dist['total_items'] > 0 else 0
        
        summary = {
            # Entryç»´åº¦æ‘˜è¦
            'entry_summary': {
                'total_orders': entry_dist['total_entries'],
                'single_item_order_ratio': single_item_ratio,
                'avg_items_per_order': entry_dist['avg_items_per_order'],
                'avg_quantity_per_order': entry_dist['avg_quantity_per_order']
            },
            
            # Itemç»´åº¦æ‘˜è¦
            'item_summary': {
                'total_items': item_dist['total_items'],
                'high_frequency_item_ratio': high_freq_item_ratio,
                'avg_orders_per_item': item_dist['avg_orders_per_item'],
                'item_concentration': (item_dist['top_items_quantity'] / qty_stats['total_quantity'] * 100) if qty_stats['total_quantity'] > 0 else 0
            },
            
            # Quantityç»´åº¦æ‘˜è¦
            'quantity_summary': {
                'total_quantity': qty_stats['total_quantity'],
                'avg_quantity_per_record': qty_stats['avg_quantity'],
                'quantity_variability': qty_stats['std_quantity'] / qty_stats['avg_quantity'] if qty_stats['avg_quantity'] > 0 else 0,
                'max_single_quantity': qty_stats['max_quantity']
            }
        }
        
        return summary
    
    def generate_optimization_suggestions(self, eiq_summary: Dict[str, Any]) -> List[str]:
        """
        ç”ŸæˆEIQä¼˜åŒ–å»ºè®®
        
        Args:
            eiq_summary: EIQåˆ†ææ‘˜è¦
            
        Returns:
            list: ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        entry_summary = eiq_summary['entry_summary']
        item_summary = eiq_summary['item_summary']
        quantity_summary = eiq_summary['quantity_summary']
        
        # Entryï¼ˆè®¢å•ï¼‰ç»´åº¦å»ºè®®
        if entry_summary['single_item_order_ratio'] > 70:
            suggestions.append("ğŸ“¦ å•å“è®¢å•å æ¯”è¾ƒé«˜(>70%)ï¼Œå»ºè®®ä¼˜åŒ–æ‹£è´§æµç¨‹ï¼Œé‡‡ç”¨å•å“æ‹£è´§ç­–ç•¥")
        elif entry_summary['single_item_order_ratio'] < 30:
            suggestions.append("ğŸ“¦ å¤šå“è®¢å•è¾ƒå¤šï¼Œå»ºè®®é‡‡ç”¨æ‰¹é‡æ‹£è´§å’Œåˆ†æ‹£ç­–ç•¥")
        
        if entry_summary['avg_items_per_order'] > 10:
            suggestions.append("ğŸ¯ è®¢å•å¹³å‡å“ç§æ•°è¾ƒå¤šï¼Œå»ºè®®ä¼˜åŒ–å­˜å‚¨å¸ƒå±€ï¼Œå°†å¸¸ç”¨å•†å“é›†ä¸­æ”¾ç½®")
        
        # Itemï¼ˆå•†å“ï¼‰ç»´åº¦å»ºè®®
        if item_summary['high_frequency_item_ratio'] < 20:
            suggestions.append("ğŸ”¥ é«˜é¢‘å•†å“å æ¯”è¾ƒä½ï¼Œå»ºè®®è¯†åˆ«æ ¸å¿ƒå•†å“å¹¶ä¼˜åŒ–å…¶å­˜å‚¨ä½ç½®")
        
        if item_summary['item_concentration'] > 80:
            suggestions.append("âš¡ å•†å“éœ€æ±‚é›†ä¸­åº¦é«˜ï¼Œå»ºè®®å¯¹çƒ­é—¨å•†å“å®æ–½é‡ç‚¹ç®¡ç†")
        elif item_summary['item_concentration'] < 50:
            suggestions.append("ğŸ“Š å•†å“éœ€æ±‚è¾ƒä¸ºåˆ†æ•£ï¼Œå»ºè®®é‡‡ç”¨ABCåˆ†æè¿›ä¸€æ­¥ç»†åŒ–ç®¡ç†")
        
        # Quantityï¼ˆæ•°é‡ï¼‰ç»´åº¦å»ºè®®
        if quantity_summary['quantity_variability'] > 2:
            suggestions.append("ğŸ“ˆ æ•°é‡å˜å¼‚æ€§è¾ƒå¤§ï¼Œå»ºè®®ä¼˜åŒ–åº“å­˜ç­–ç•¥ï¼Œå¢å¼ºéœ€æ±‚é¢„æµ‹")
        
        if quantity_summary['avg_quantity_per_record'] < 2:
            suggestions.append("ğŸ”¢ å¹³å‡å•æ¬¡éœ€æ±‚é‡è¾ƒå°ï¼Œå»ºè®®è€ƒè™‘å°åŒ…è£…ç­–ç•¥")
        elif quantity_summary['avg_quantity_per_record'] > 20:
            suggestions.append("ğŸ“¦ å¹³å‡å•æ¬¡éœ€æ±‚é‡è¾ƒå¤§ï¼Œå»ºè®®ä¼˜åŒ–åŒ…è£…å’Œè¿è¾“æ–¹å¼")
        
        return suggestions
    
    def analyze_batch(self, df: pd.DataFrame, entry_column: str, 
                     item_column: str, quantity_column: str, 
                     date_column: Optional[str] = None) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """
        æ‰¹é‡æ‰§è¡ŒEIQåˆ†æ
        
        Args:
            df: æ•°æ®æ¡†
            entry_column: è®¢å•åˆ—å
            item_column: å•†å“åˆ—å
            quantity_column: æ•°é‡åˆ—å
            date_column: æ—¥æœŸåˆ—åï¼ˆå¯é€‰ï¼‰
            
        Returns:
            tuple: (EIQåˆ†æç»“æœ, ç»¼åˆæ‘˜è¦)
        """
        # æ•°æ®éªŒè¯
        is_valid, errors = self.validate_data(df, entry_column, item_column, quantity_column, date_column)
        if not is_valid:
            raise ValueError(f"æ•°æ®éªŒè¯å¤±è´¥: {'; '.join(errors)}")
        
        # æ‰§è¡Œå„ç»´åº¦åˆ†æ
        entry_analysis = self.analyze_entry_patterns(df, entry_column, item_column, quantity_column)
        item_analysis = self.analyze_item_patterns(df, entry_column, item_column, quantity_column)
        quantity_analysis = self.analyze_quantity_patterns(df, entry_column, item_column, quantity_column)
        
        # ç”Ÿæˆç»¼åˆæ‘˜è¦
        eiq_summary = self.generate_eiq_summary(entry_analysis, item_analysis, quantity_analysis)
        
        # ç»„åˆå®Œæ•´ç»“æœ
        eiq_results = {
            'entry_analysis': entry_analysis,
            'item_analysis': item_analysis, 
            'quantity_analysis': quantity_analysis,
            'eiq_summary': eiq_summary
        }
        
        return eiq_results, eiq_summary 