# -*- coding: utf-8 -*-
"""
å…¥åº“é€šç”¨åˆ†ææ¨¡å— - ä¸“é—¨å¤„ç†å…¥åº“æ•°æ®çš„æ—¶é—´åºåˆ—åˆ†æ
"""

import pandas as pd
import numpy as np
import streamlit as st
import plotly.graph_objects as go
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

class InboundAnalyzer:
    """å…¥åº“é€šç”¨åˆ†æå™¨"""
    
    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–å…¥åº“åˆ†æå™¨
        
        Args:
            config: åˆ†æé…ç½®å‚æ•°
        """
        self.config = config
        
    def clean_date_column(self, df: pd.DataFrame, date_column: str) -> pd.DataFrame:
        """
        æ¸…ç†æ—¥æœŸåˆ—ï¼Œä¿æŒä¸ºdatetimeæ ¼å¼ä»¥ä¾¿åç»­å¤„ç†
        
        Args:
            df: æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            
        Returns:
            pd.DataFrame: æ¸…ç†åçš„æ•°æ®æ¡†
        """
        df_clean = df.copy()
        
        try:
            # å°è¯•è½¬æ¢ä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼
            df_clean[date_column] = pd.to_datetime(df_clean[date_column], errors='coerce')
            
            # åˆ é™¤æ— æ³•è§£æçš„æ—¥æœŸè¡Œ
            df_clean = df_clean.dropna(subset=[date_column])
            
            st.info(f"ğŸ“… æ—¥æœŸåˆ—å·²æ¸…ç†ï¼šä¿ç•™ {len(df_clean)} è¡Œæœ‰æ•ˆæ—¥æœŸæ•°æ®")
            
        except Exception as e:
            st.error(f"âŒ æ—¥æœŸåˆ—æ¸…ç†å¤±è´¥: {str(e)}")
            return df
            
        return df_clean
        
    def aggregate_daily_data(self, df: pd.DataFrame, date_column: str, 
                           sku_column: Optional[str] = None,
                           quantity_column: Optional[str] = None) -> pd.DataFrame:
        """
        æŒ‰æ—¥æœŸèšåˆå…¥åº“æ•°æ®
        
        Args:
            df: æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            sku_column: SKUæ•°åˆ—åï¼ˆå¯é€‰ï¼‰
            quantity_column: ä»¶æ•°åˆ—åï¼ˆå¯é€‰ï¼‰
            
        Returns:
            pd.DataFrame: èšåˆåçš„æ—¥æœŸæ•°æ®
        """
        try:
            # å‡†å¤‡èšåˆå­—å…¸
            agg_dict = {}
                
            # å¦‚æœæœ‰SKUåˆ—ï¼Œè®¡ç®—æ¯æ—¥å…¥åº“SKUæ•°ï¼ˆå»é‡ï¼‰
            if sku_column and sku_column in df.columns:
                agg_dict[f'æ—¥å…¥SKUæ•°'] = (sku_column, 'nunique')
                
            # å¦‚æœæœ‰æ•°é‡åˆ—ï¼Œè®¡ç®—æ¯æ—¥å…¥åº“ä»¶æ•°æ€»å’Œ
            if quantity_column and quantity_column in df.columns:
                agg_dict[f'æ—¥å…¥ä»¶æ•°'] = (quantity_column, 'sum')
            
            if not agg_dict:
                st.warning("âš ï¸ æ²¡æœ‰å¯èšåˆçš„æ•°æ®åˆ—")
                return pd.DataFrame()
            
            # æŒ‰æ—¥æœŸåˆ†ç»„èšåˆ
            daily_data = df.groupby(date_column).agg(agg_dict).reset_index()
            
            # å¤„ç†åˆ—åï¼ˆå¤„ç†pandasèšåˆåçš„å¤šçº§ç´¢å¼•ï¼‰
            if isinstance(daily_data.columns, pd.MultiIndex):
                # å¤„ç†å¤šçº§ç´¢å¼•ï¼šä¿ç•™ç¬¬ä¸€åˆ—(æ—¥æœŸåˆ—)ï¼Œå…¶ä»–åˆ—ä½¿ç”¨èšåˆå­—å…¸çš„é”®å
                new_columns = [daily_data.columns[0][0]]  # æ—¥æœŸåˆ—
                new_columns.extend(list(agg_dict.keys()))  # èšåˆæŒ‡æ ‡å
                daily_data.columns = new_columns
            else:
                # å¦‚æœä¸æ˜¯å¤šçº§ç´¢å¼•ï¼Œæ£€æŸ¥åˆ—åé•¿åº¦
                if len(daily_data.columns) != len(agg_dict) + 1:
                    new_columns = [daily_data.columns[0]]  # ä¿ç•™ç¬¬ä¸€åˆ—(æ—¥æœŸåˆ—)
                    new_columns.extend(list(agg_dict.keys()))  # æ·»åŠ èšåˆæŒ‡æ ‡å
                    daily_data.columns = new_columns
            
            # æŒ‰æ—¥æœŸæ’åº
            daily_data = daily_data.sort_values(date_column)
            
            st.success(f"âœ… æ•°æ®èšåˆå®Œæˆï¼šå…± {len(daily_data)} å¤©çš„å…¥åº“æ•°æ®")
                
            return daily_data
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®èšåˆå¤±è´¥: {str(e)}")
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            st.error(f"è°ƒè¯•ä¿¡æ¯ï¼šdate_column={date_column}, agg_dict={agg_dict}")
            if 'df' in locals():
                st.error(f"æ•°æ®æ¡†åˆ—å: {list(df.columns)}")
            return pd.DataFrame()
    
    def filter_date_range(self, df: pd.DataFrame, date_column: str, 
                         start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """
        æ ¹æ®æ—¥æœŸèŒƒå›´è¿‡æ»¤æ•°æ®
        
        Args:
            df: æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            pd.DataFrame: è¿‡æ»¤åçš„æ•°æ®
        """
        try:

            
            # è½¬æ¢è¾“å…¥çš„æ—¥æœŸå‚æ•°
            if isinstance(start_date, str):
                start_date = pd.to_datetime(start_date).date()
            elif hasattr(start_date, 'date'):
                start_date = start_date.date()
                
            if isinstance(end_date, str):
                end_date = pd.to_datetime(end_date).date()
            elif hasattr(end_date, 'date'):
                end_date = end_date.date()
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
            df[date_column] = pd.to_datetime(df[date_column])
            
            # è½¬æ¢ä¸ºæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
            df_dates = df[date_column].dt.date
            
            # è¿‡æ»¤æ—¥æœŸèŒƒå›´
            mask = (df_dates >= start_date) & (df_dates <= end_date)
            filtered_df = df[mask]
            
            st.info(f"ğŸ“Š æ—¥æœŸè¿‡æ»¤ï¼š{start_date} è‡³ {end_date}ï¼Œå…± {len(filtered_df)} æ¡è®°å½•")
            
            return filtered_df
            
        except Exception as e:
            st.error(f"âŒ æ—¥æœŸè¿‡æ»¤å¤±è´¥: {str(e)}")

            return df
    
    def analyze_batch(self, df: pd.DataFrame, date_column: str,
                     sku_column: Optional[str] = None,
                     quantity_column: Optional[str] = None,
                     start_date: Optional[datetime] = None,
                     end_date: Optional[datetime] = None) -> Tuple[pd.DataFrame, Dict]:
        """
        æ‰¹é‡åˆ†æå…¥åº“æ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            sku_column: SKUæ•°åˆ—å
            quantity_column: ä»¶æ•°åˆ—å
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            Tuple[pd.DataFrame, Dict]: (èšåˆåçš„æ—¥æœŸæ•°æ®, ç»Ÿè®¡æ‘˜è¦)
        """
        try:
            # 1. æ¸…ç†æ—¥æœŸåˆ—
            df_cleaned = self.clean_date_column(df, date_column)
            
            if df_cleaned.empty:
                return pd.DataFrame(), {}
            
            # 2. æ—¥æœŸè¿‡æ»¤
            if start_date and end_date:
                df_cleaned = self.filter_date_range(df_cleaned, date_column, start_date, end_date)
            
            # 3. æŒ‰æ—¥èšåˆæ•°æ®
            daily_data = self.aggregate_daily_data(
                df_cleaned, date_column, sku_column, quantity_column
            )
            
            if daily_data.empty:
                return pd.DataFrame(), {}
            
            # 4. ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
            summary = self.generate_summary_statistics(daily_data, date_column)
            
            return daily_data, summary
            
        except Exception as e:
            st.error(f"âŒ å…¥åº“åˆ†æå¤±è´¥: {str(e)}")
            return pd.DataFrame(), {}
    
    def calculate_average_without_outliers(self, data: pd.Series) -> float:
        """
        è®¡ç®—å‰”é™¤ç¦»ç¾¤å€¼åçš„å¹³å‡æ•°
        
        Args:
            data: æ•°æ®åºåˆ—
            
        Returns:
            float: å‰”é™¤ç¦»ç¾¤å€¼åçš„å¹³å‡æ•°
        """
        try:
            if len(data) < 4:  # æ•°æ®ç‚¹å¤ªå°‘ï¼Œç›´æ¥è¿”å›å¹³å‡æ•°
                return data.mean()
            
            # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹ç¦»ç¾¤å€¼
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            
            # å®šä¹‰ç¦»ç¾¤å€¼èŒƒå›´
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            # è¿‡æ»¤ç¦»ç¾¤å€¼
            filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]
            
            # å¦‚æœè¿‡æ»¤åæ•°æ®å¤ªå°‘ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
            if len(filtered_data) < len(data) * 0.5:  # å¦‚æœå‰”é™¤äº†è¶…è¿‡50%çš„æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                return data.mean()
            
            return filtered_data.mean()
            
        except Exception as e:
            return data.mean()  # å‡ºé”™æ—¶è¿”å›æ™®é€šå¹³å‡æ•°
    
    def filter_outliers_98_percentile(self, data: pd.Series) -> pd.Series:
        """
        å•å‘è¿‡æ»¤ï¼šåªè¿‡æ»¤å¼‚å¸¸ä½å€¼ï¼Œä¿ç•™æ‰€æœ‰é«˜å€¼
        ç‰¹åˆ«é’ˆå¯¹ï¼šè®¢å•æ•°ã€SKUæ•°ã€ä»¶æ•°ç­‰ä¸šåŠ¡æŒ‡æ ‡ä¸­çš„å¼‚å¸¸ä½å€¼ï¼ˆå¦‚1-2ï¼‰
        
        Args:
            data: æ•°æ®åºåˆ—
            
        Returns:
            pd.Series: è¿‡æ»¤åçš„æ•°æ®åºåˆ—
        """
        try:
            if len(data) < 10:  # æ•°æ®ç‚¹å¤ªå°‘ï¼Œè¿”å›åŸå§‹æ•°æ®
                return data
            
            # ğŸ” ç¬¬ä¸€æ­¥ï¼šåˆ†ææ•°æ®çš„åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
            median = data.median()
            q1 = data.quantile(0.25)
            q3 = data.quantile(0.75)
            mean_val = data.mean()
            
            print(f"æ•°æ®åˆ†æ - ä¸­ä½æ•°: {median:.1f}, Q1: {q1:.1f}, Q3: {q3:.1f}, å‡å€¼: {mean_val:.1f}")
            
            # ğŸ” ç¬¬äºŒæ­¥ï¼šè¯†åˆ«å¼‚å¸¸ä½å€¼ï¼ˆä¸šåŠ¡é€»è¾‘åˆ¤æ–­ï¼‰
            # å¯¹äºè®¢å•æ•°ã€SKUæ•°ã€ä»¶æ•°ç­‰ä¸šåŠ¡æŒ‡æ ‡ï¼Œå°äº10çš„å€¼é€šå¸¸æ˜¯å¼‚å¸¸çš„
            if median > 50:  # æ­£å¸¸ä¸šåŠ¡æ•°æ®çš„ä¸­ä½æ•°åº”è¯¥æ¯”è¾ƒå¤§
                min_business_value = max(10, q1 * 0.1)  # ä¸šåŠ¡æœ€å°å€¼ä¸åº”å°äºQ1çš„10%ï¼Œä¸”ä¸å°äº10
                print(f"ä¸šåŠ¡æœ€å°å€¼é˜ˆå€¼: {min_business_value:.1f}")
            else:
                min_business_value = max(1, median * 0.1)  # å¯¹äºè¾ƒå°çš„æ•°æ®ï¼Œå…è®¸æ›´å°çš„å€¼
                print(f"ä¸šåŠ¡æœ€å°å€¼é˜ˆå€¼ï¼ˆå°æ•°æ®ï¼‰: {min_business_value:.1f}")
            
            # ğŸ” ç¬¬ä¸‰æ­¥ï¼šä¸è®¾ç½®ä¸Šè¾¹ç•Œï¼Œä¿ç•™æ‰€æœ‰é«˜å€¼
            # æ³¨é‡Šæ‰ä¸Šè¾¹ç•Œè®¡ç®—ï¼Œåªä¿ç•™ä¸‹è¾¹ç•Œè¿‡æ»¤
            # è¿™æ ·å¯ä»¥ä¿ç•™ä¸šåŠ¡ä¸­çš„æ‰€æœ‰é«˜å³°å€¼æ•°æ®
            
            # ğŸ” ç¬¬å››æ­¥ï¼šåªåº”ç”¨ä¸‹è¾¹ç•Œè¿‡æ»¤ï¼Œä¿ç•™æ‰€æœ‰é«˜å€¼
            filtered_data = data[data >= min_business_value]
            
            # ğŸ” ç¬¬äº”æ­¥ï¼šå®‰å…¨æ£€æŸ¥
            if len(filtered_data) < len(data) * 0.3:  # å¦‚æœè¿‡æ»¤æ‰è¶…è¿‡70%çš„æ•°æ®
                print("è¿‡æ»¤è¿‡äºä¸¥æ ¼ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                # ä½¿ç”¨æ›´å®½æ¾çš„5%åˆ†ä½æ•°ä½œä¸ºä¸‹è¾¹ç•Œ
                lower_backup = data.quantile(0.05)
                filtered_data = data[data >= lower_backup]
            
            print(f"å•å‘è¿‡æ»¤ç»“æœ - åŸå§‹: {len(data)}ä¸ª, è¿‡æ»¤å: {len(filtered_data)}ä¸ª, ç§»é™¤ä½å€¼: {len(data) - len(filtered_data)}ä¸ª")
            print(f"è¿‡æ»¤åèŒƒå›´: {filtered_data.min():.1f} ~ {filtered_data.max():.1f} (ä¿ç•™æ‰€æœ‰é«˜å€¼)")
            
            return filtered_data if len(filtered_data) >= 5 else data
            
        except Exception as e:
            print(f"è¿‡æ»¤å‡ºé”™: {str(e)}")
            return data  # å‡ºé”™æ—¶è¿”å›åŸå§‹æ•°æ®

    def generate_summary_statistics(self, daily_data: pd.DataFrame, date_column: str) -> Dict:
        """
        ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        
        Args:
            daily_data: æ—¥èšåˆæ•°æ®
            date_column: æ—¥æœŸåˆ—å
            
        Returns:
            Dict: ç»Ÿè®¡æ‘˜è¦
        """
        try:
            summary = {
                'date_range': {
                    'start_date': daily_data[date_column].min(),
                    'end_date': daily_data[date_column].max(),
                    'total_days': len(daily_data)
                }
            }
            
            # è®¡ç®—å„ç»´åº¦çš„ç»Ÿè®¡ä¿¡æ¯
            for col in daily_data.columns:
                if col != date_column and daily_data[col].dtype in ['int64', 'float64']:
                    avg_without_outliers = self.calculate_average_without_outliers(daily_data[col])
                    
                    # ä½¿ç”¨98%åˆ†ä½æ•°è¿‡æ»¤ç¦»ç¾¤å€¼ï¼Œç„¶åè®¡ç®—çœŸæ­£çš„æœ€å¤§æœ€å°å€¼
                    filtered_data = self.filter_outliers_98_percentile(daily_data[col])
                    
                    # åœ¨è¿‡æ»¤åçš„æ•°æ®ä¸­æ‰¾åˆ°æœ€é«˜å’Œæœ€ä½ç‚¹
                    if len(filtered_data) > 0:
                        filtered_max = filtered_data.max()
                        filtered_min = filtered_data.min()
                        
                        # æ‰¾åˆ°å¯¹åº”çš„æ—¥æœŸï¼ˆåœ¨åŸå§‹æ•°æ®ä¸­ï¼‰
                        max_mask = daily_data[col] == filtered_max
                        min_mask = daily_data[col] == filtered_min
                        
                        # å¦‚æœæœ‰å¤šä¸ªç›¸åŒçš„æœ€å¤§/æœ€å°å€¼ï¼Œå–ç¬¬ä¸€ä¸ª
                        max_date = daily_data.loc[max_mask, date_column].iloc[0] if max_mask.any() else daily_data.loc[daily_data[col].idxmax(), date_column]
                        min_date = daily_data.loc[min_mask, date_column].iloc[0] if min_mask.any() else daily_data.loc[daily_data[col].idxmin(), date_column]
                    else:
                        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
                        filtered_max = daily_data[col].max()
                        filtered_min = daily_data[col].min()
                        max_date = daily_data.loc[daily_data[col].idxmax(), date_column]
                        min_date = daily_data.loc[daily_data[col].idxmin(), date_column]
                    
                    summary[col] = {
                        'total': daily_data[col].sum(),
                        'daily_avg': daily_data[col].mean(),
                        'daily_avg_no_outliers': avg_without_outliers,  # å‰”é™¤ç¦»ç¾¤å€¼åçš„å¹³å‡æ•°
                        'daily_max': filtered_max,  # ä½¿ç”¨è¿‡æ»¤åçš„æœ€å¤§å€¼
                        'daily_min': filtered_min,  # ä½¿ç”¨è¿‡æ»¤åçš„æœ€å°å€¼
                        'max_date': max_date,  # æœ€é«˜ç‚¹æ—¥æœŸ
                        'min_date': min_date,  # æœ€ä½ç‚¹æ—¥æœŸ
                        'trend': 'increasing' if daily_data[col].iloc[-1] > daily_data[col].iloc[0] else 'decreasing'
                    }
            
            return summary
            
        except Exception as e:
            st.error(f"âŒ ç»Ÿè®¡æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {}
    
    def render_trend_chart(self, daily_data: pd.DataFrame, date_column: str, summary: Dict = None) -> None:
        """
        æ¸²æŸ“è¶‹åŠ¿æŠ˜çº¿å›¾
        
        Args:
            daily_data: æ—¥èšåˆæ•°æ®
            date_column: æ—¥æœŸåˆ—å
            summary: ç»Ÿè®¡æ‘˜è¦ï¼ˆåŒ…å«å¹³å‡æ•°ä¿¡æ¯ï¼‰
        """
        try:
            if daily_data.empty:
                st.warning("âš ï¸ æ²¡æœ‰æ•°æ®å¯ä¾›ç»˜å›¾")
                return
            
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå¯¹å¤§æ•°æ®é›†è¿›è¡Œæ™ºèƒ½é‡‡æ ·
            sample_data = daily_data.copy()
            original_count = len(daily_data)
            
            if len(daily_data) > 1000:  # è¶…è¿‡1000ä¸ªç‚¹æ—¶è¿›è¡Œé‡‡æ ·
                # è®¡ç®—é‡‡æ ·æ¯”ä¾‹ï¼Œæœ€å¤šä¿ç•™1000ä¸ªç‚¹
                sample_ratio = min(1000 / len(daily_data), 1.0)
                sample_data = daily_data.sample(frac=sample_ratio, random_state=42).sort_values(date_column)
                st.info(f"ğŸ“Š å›¾è¡¨æ€§èƒ½ä¼˜åŒ–ï¼šä» {original_count:,} ä¸ªæ•°æ®ç‚¹é‡‡æ · {len(sample_data):,} ä¸ªç‚¹ä»¥æå‡äº¤äº’æ€§èƒ½")
            
            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()
            
            # ä¼˜åŒ–çš„é¢œè‰²å’Œæ ·å¼é…ç½® - é¿å…é¢œè‰²é‡å 
            colors = ['#ff6b35', '#004e89', '#009ffd', '#00d4aa', '#ffbc42']
            line_styles = ['solid', 'dash', 'dot', 'dashdot']
            marker_symbols = ['circle', 'square', 'diamond', 'triangle-up', 'star']
            
            color_idx = 0
            
            for col in sample_data.columns:
                if col != date_column and sample_data[col].dtype in ['int64', 'float64']:
                    # è°ƒæ•´çº¿æ¡æ ·å¼ï¼Œé¿å…é‡å 
                    line_width = 3 if color_idx == 0 else 2  # ç¬¬ä¸€æ¡çº¿æ›´ç²—
                    marker_size = 6 if color_idx == 0 else 4  # ç¬¬ä¸€æ¡çº¿çš„ç‚¹æ›´å¤§
                    opacity = 0.9 if color_idx == 0 else 0.8  # ç¬¬ä¸€æ¡çº¿æ›´ä¸é€æ˜
                    
                    fig.add_trace(go.Scatter(
                        x=sample_data[date_column],
                        y=sample_data[col],
                        mode='lines+markers',
                        name=col,
                        line=dict(
                            color=colors[color_idx % len(colors)], 
                            width=line_width,
                            dash=line_styles[color_idx % len(line_styles)] if color_idx > 0 else 'solid'
                        ),
                        marker=dict(
                            size=marker_size,
                            symbol=marker_symbols[color_idx % len(marker_symbols)],
                            opacity=opacity
                        ),
                        opacity=opacity,
                        hovertemplate=f'<b>{col}</b><br>æ—¥æœŸ: %{{x}}<br>æ•°é‡: %{{y:,.0f}}<extra></extra>'
                    ))
                    color_idx += 1
            
            # ğŸ”¹ æ·»åŠ æœ€é«˜æœ€ä½ç‚¹æ ‡æ³¨
            if summary:
                point_color_idx = 0
                for col in sample_data.columns:
                    if col != date_column and sample_data[col].dtype in ['int64', 'float64']:
                        col_summary = summary.get(col, {})
                        line_color = colors[point_color_idx % len(colors)]
                        
                        # æ·»åŠ æœ€é«˜ç‚¹æ ‡æ³¨
                        if 'daily_max' in col_summary and 'max_date' in col_summary:
                            max_value = col_summary['daily_max']
                            max_date = col_summary['max_date']
                            
                            fig.add_annotation(
                                x=max_date,
                                y=max_value,
                                xref="x", 
                                yref="y",
                                text=f"ğŸ”´ æœ€é«˜: {max_value:.0f}",
                                font=dict(color=line_color, size=10, family="Arial"),
                                bgcolor="rgba(255,255,255,0.9)",
                                bordercolor=line_color,
                                borderwidth=1,
                                showarrow=True,
                                arrowhead=2,
                                arrowsize=1,
                                arrowwidth=2,
                                arrowcolor=line_color,
                                ax=0,
                                ay=-25  # æ ‡æ³¨åœ¨ç‚¹ä¸Šæ–¹
                            )
                        
                        # æ·»åŠ æœ€ä½ç‚¹æ ‡æ³¨
                        if 'daily_min' in col_summary and 'min_date' in col_summary:
                            min_value = col_summary['daily_min']
                            min_date = col_summary['min_date']
                            
                            fig.add_annotation(
                                x=min_date,
                                y=min_value,
                                xref="x", 
                                yref="y",
                                text=f"ğŸ”µ æœ€ä½: {min_value:.0f}",
                                font=dict(color=line_color, size=10, family="Arial"),
                                bgcolor="rgba(255,255,255,0.9)",
                                bordercolor=line_color,
                                borderwidth=1,
                                showarrow=True,
                                arrowhead=2,
                                arrowsize=1,
                                arrowwidth=2,
                                arrowcolor=line_color,
                                ax=0,
                                ay=25   # æ ‡æ³¨åœ¨ç‚¹ä¸‹æ–¹
                            )
                        point_color_idx += 1
            
            # ğŸ”¹ æ·»åŠ å¹³å‡æ•°çº¿ï¼ˆå‰”é™¤ç¦»ç¾¤å€¼ï¼‰- é¢œè‰²åŒ¹é…æ•°æ®çº¿ï¼Œå¸¦æ•°å€¼æ ‡æ³¨
            if summary:
                avg_color_idx = 0
                avg_texts = []  # æ”¶é›†æ‰€æœ‰å¹³å‡å€¼æ–‡æœ¬ï¼Œç»Ÿä¸€æ˜¾ç¤ºåœ¨å³ä¸Šè§’
                
                for col in sample_data.columns:
                    if col != date_column and sample_data[col].dtype in ['int64', 'float64']:
                        col_summary = summary.get(col, {})
                        avg_no_outliers = col_summary.get('daily_avg_no_outliers')
                        
                        if avg_no_outliers is not None:
                            # ä½¿ç”¨ä¸æ•°æ®çº¿ç›¸åŒçš„é¢œè‰²
                            line_color = colors[avg_color_idx % len(colors)]
                            
                            # æ·»åŠ æ°´å¹³å¹³å‡çº¿
                            fig.add_hline(
                                y=avg_no_outliers,
                                line_dash="dot",
                                line_width=1.5,  # çº¿æ¡å˜ç»†
                                line_color=line_color,
                                opacity=0.8
                            )
                            
                            # æ”¶é›†å¹³å‡å€¼æ–‡æœ¬ï¼Œç”¨äºå³ä¸Šè§’æ˜¾ç¤º
                            avg_texts.append(f"<span style='color:{line_color}'>â—</span> {col} å¹³å‡: {avg_no_outliers:.1f}")
                            avg_color_idx += 1
                
                # ğŸ“Š åœ¨å³ä¸Šè§’ç»Ÿä¸€æ˜¾ç¤ºæ‰€æœ‰å¹³å‡å€¼
                if avg_texts:
                    avg_text_combined = "<br>".join(avg_texts)
                    fig.add_annotation(
                        x=1,  # å³ä¾§
                        y=1,  # é¡¶éƒ¨
                        xref="paper",  # ä½¿ç”¨çº¸å¼ åæ ‡
                        yref="paper",
                        text=avg_text_combined,
                        font=dict(color='white', size=11),
                        bgcolor="rgba(17,17,17,0.9)",  # ä¸å›¾è¡¨èƒŒæ™¯ä¸€è‡´çš„æ·±è‰²
                        bordercolor="rgba(128,128,128,0.5)",
                        borderwidth=1,
                        showarrow=False,
                        xanchor="right",
                        yanchor="top",
                        align="left"
                    )
            
            # ğŸ”§ è®¡ç®—Yè½´çš„åˆé€‚èŒƒå›´
            y_min_overall = float('inf')
            y_max_overall = 0
            
            for col in sample_data.columns:
                if col != date_column and sample_data[col].dtype in ['int64', 'float64']:
                    col_min = sample_data[col].min()
                    col_max = sample_data[col].max()
                    y_min_overall = min(y_min_overall, col_min)
                    y_max_overall = max(y_max_overall, col_max)
            
            # è®¡ç®—åˆé€‚çš„Yè½´è¾¹ç•Œï¼Œç•™10%çš„ç©ºé—´ç”¨äºè§†è§‰æ•ˆæœ
            if y_min_overall != float('inf'):
                y_range = y_max_overall - y_min_overall
                margin = y_range * 0.1  # 10%çš„è¾¹è·
                y_axis_min = max(0, y_min_overall - margin)  # ä¸ä½äº0
                y_axis_max = y_max_overall + margin
                
    
            else:
                y_axis_min = None
                y_axis_max = None
            
            # å›¾è¡¨æ ·å¼è®¾ç½®
            fig.update_layout(
                title=dict(
                    text="<b>å…¥åº“æ•°æ®è¶‹åŠ¿åˆ†æ</b>",
                    x=0.5,
                    font=dict(size=18, color='white')
                ),
                xaxis=dict(
                    title="<b>æ—¥æœŸ</b>",
                    title_font=dict(size=14, color='white'),
                    tickfont=dict(color='white'),
                    showgrid=True,
                    gridcolor='rgba(128,128,128,0.3)'
                ),
                yaxis=dict(
                    title="<b>æ•°é‡</b>",
                    title_font=dict(size=14, color='white'),
                    tickfont=dict(color='white'),
                    type="linear",  # ä½¿ç”¨çº¿æ€§åˆ»åº¦è€Œä¸æ˜¯å¯¹æ•°åˆ»åº¦
                    showgrid=True,
                    gridcolor='rgba(128,128,128,0.3)',
                    range=[y_axis_min, y_axis_max] if y_axis_min is not None else None,  # è®¾ç½®Yè½´èŒƒå›´
                    autorange=False if y_axis_min is not None else True  # ç¦ç”¨è‡ªåŠ¨èŒƒå›´
                ),
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1,
                    font=dict(color='white'),
                    bgcolor='rgba(0,0,0,0.5)'  # å›¾ä¾‹èƒŒæ™¯
                ),
                plot_bgcolor='rgba(17, 17, 17, 0.8)',
                paper_bgcolor='rgba(17, 17, 17, 0.8)',
                font=dict(color='white'),
                height=500,
                hovermode='x unified'
            )
            
            # ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šå‡å°‘æ¸²æŸ“å¤æ‚åº¦
            fig.update_traces(
                connectgaps=False,  # ä¸è¿æ¥ç¼ºå¤±æ•°æ®çš„é—´éš™
                line_smoothing=0.5  # é€‚åº¦å¹³æ»‘
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"âŒ å›¾è¡¨æ¸²æŸ“å¤±è´¥: {str(e)}")
    
    def generate_optimization_suggestions(self, daily_data: pd.DataFrame, summary: Dict) -> List[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®ï¼ˆåŒ…å«è¯¦ç»†ç»Ÿè®¡æ•°æ®ï¼‰
        
        Args:
            daily_data: æ—¥èšåˆæ•°æ®
            summary: ç»Ÿè®¡æ‘˜è¦
            
        Returns:
            List[str]: ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        suggestions = []
        
        try:
            # ğŸ“Š æ·»åŠ æ•°æ®ç»Ÿè®¡æ‘˜è¦
            date_range = summary.get('date_range', {})
            if date_range:
                start_date = date_range.get('start_date', 'æœªçŸ¥')
                end_date = date_range.get('end_date', 'æœªçŸ¥')
                total_days = date_range.get('total_days', 0)
                suggestions.append(f"ğŸ“… **åˆ†æå‘¨æœŸ**: {start_date} è‡³ {end_date}ï¼Œå…± {total_days} å¤©")
            
            # ğŸ“ˆ æ·»åŠ å„ç»´åº¦çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            for col, stats in summary.items():
                if isinstance(stats, dict) and 'daily_avg_no_outliers' in stats:
                    avg_no_outliers = stats.get('daily_avg_no_outliers', 0)
                    daily_max = stats.get('daily_max', 0)
                    daily_min = stats.get('daily_min', 0)
                    max_date = stats.get('max_date', 'æœªçŸ¥')
                    min_date = stats.get('min_date', 'æœªçŸ¥')
                    
                    suggestions.append(
                        f"ğŸ“Š **{col}**: "
                        f"å¹³å‡ {avg_no_outliers:.1f}/å¤© | "
                        f"æœ€é«˜ {daily_max:.0f} ({max_date}) | "
                        f"æœ€ä½ {daily_min:.0f} ({min_date})"
                    )
                    
                    # è¶‹åŠ¿åˆ†æå»ºè®®
                    if stats.get('trend') == 'increasing':
                        suggestions.append(f"ğŸ“ˆ {col}å‘ˆä¸Šå‡è¶‹åŠ¿ï¼Œå»ºè®®å…³æ³¨åº“å­˜å®¹é‡è§„åˆ’")
                    elif daily_max > avg_no_outliers * 2:
                        suggestions.append(f"âš ï¸ {col}æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®åˆ†æå…¥åº“é«˜å³°æœŸçš„å¤„ç†èƒ½åŠ›")
            
            # åŸºäºæ•°æ®åˆ†å¸ƒçš„å»ºè®®
            if len(daily_data) >= 7:
                suggestions.append("ğŸ“… å»ºè®®æŒ‰å‘¨/æœˆç»´åº¦åˆ†æå…¥åº“è§„å¾‹ï¼Œä¼˜åŒ–æ”¶è´§è®¡åˆ’")
            
            if len([s for s in suggestions if not s.startswith("ğŸ“Š") and not s.startswith("ğŸ“…")]) == 0:
                suggestions.append("ğŸ’¡ å…¥åº“æ•°æ®è¡¨ç°å¹³ç¨³ï¼Œå»ºè®®æŒç»­ç›‘æ§åº“å­˜å‘¨è½¬ç‡")
                
        except Exception as e:
            suggestions.append(f"âš ï¸ å»ºè®®ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            
        return suggestions
    
    def aggregate_daily_data_enhanced(self, df: pd.DataFrame, date_column: str,
                                    sku_column: Optional[str] = None,
                                    sku_count_column: Optional[str] = None,
                                    quantity_column: Optional[str] = None,
                                    quantity_count_column: Optional[str] = None) -> pd.DataFrame:
        """
        å¢å¼ºçš„æŒ‰æ—¥æœŸèšåˆå…¥åº“æ•°æ®ï¼Œæ”¯æŒåŸå§‹æ•°æ®å’Œèšåˆæ•°æ®
        
        Args:
            df: æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            sku_column: SKUåˆ—åï¼ˆåŸå§‹ï¼‰
            sku_count_column: SKUæ•°/å¤©åˆ—åï¼ˆèšåˆï¼‰
            quantity_column: ä»¶æ•°åˆ—åï¼ˆåŸå§‹ï¼‰
            quantity_count_column: ä»¶æ•°/å¤©åˆ—åï¼ˆèšåˆï¼‰
            
        Returns:
            pd.DataFrame: èšåˆåçš„æ—¥æœŸæ•°æ®
        """
        try:
            # å‡†å¤‡èšåˆå­—å…¸
            agg_dict = {}
            data_sources = []
            
            # SKUæ•°æ®å¤„ç†
            if sku_column and sku_column in df.columns:
                agg_dict['SKUæ•°/å¤©'] = (sku_column, 'nunique')
                data_sources.append(f"ğŸ”¹ åŸå§‹SKUæ•°æ®ï¼š{sku_column}åˆ—ï¼ŒæŒ‰æ—¥æœŸå»é‡è®¡ç®—SKUæ•°/å¤©")
            elif sku_count_column and sku_count_column in df.columns:
                agg_dict['SKUæ•°/å¤©'] = (sku_count_column, 'sum')
                data_sources.append(f"ğŸ”¹ èšåˆSKUæ•°æ®ï¼š{sku_count_column}åˆ—ï¼Œç›´æ¥æŒ‰æ—¥æœŸæ±‡æ€»")
            
            # ä»¶æ•°æ•°æ®å¤„ç†
            if quantity_column and quantity_column in df.columns:
                agg_dict['ä»¶æ•°/å¤©'] = (quantity_column, 'sum')
                data_sources.append(f"ğŸ”¹ åŸå§‹ä»¶æ•°æ•°æ®ï¼š{quantity_column}åˆ—ï¼ŒæŒ‰æ—¥æœŸæ±‚å’Œè®¡ç®—ä»¶æ•°/å¤©")
            elif quantity_count_column and quantity_count_column in df.columns:
                agg_dict['ä»¶æ•°/å¤©'] = (quantity_count_column, 'sum')
                data_sources.append(f"ğŸ”¹ èšåˆä»¶æ•°æ•°æ®ï¼š{quantity_count_column}åˆ—ï¼Œç›´æ¥æŒ‰æ—¥æœŸæ±‡æ€»")
            
            if not agg_dict:
                st.warning("âš ï¸ æ²¡æœ‰å¯èšåˆçš„æ•°æ®åˆ—")
                return pd.DataFrame()
            
            # æ˜¾ç¤ºæ•°æ®å¤„ç†æ–¹å¼
            st.success("âœ… **æ•°æ®å¤„ç†æ–¹å¼**ï¼š\n" + "\n".join(data_sources))
            
            # éªŒè¯æºåˆ—æ˜¯å¦å­˜åœ¨
            missing_columns = []
            for metric_name, (col_name, agg_func) in agg_dict.items():
                if col_name not in df.columns:
                    missing_columns.append(col_name)
            
            if missing_columns:
                st.error(f"âŒ ç¼ºå¤±çš„æºåˆ—: {missing_columns}")
                return pd.DataFrame()
            
            # æ‰§è¡Œèšåˆ - ä½¿ç”¨ç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼ˆå‚è€ƒå‡ºåº“åˆ†æï¼‰
            try:
                # å…ˆæŒ‰ç°æœ‰åˆ—åèšåˆï¼Œåç»­é‡å‘½å
                simple_agg_dict = {}
                target_column_names = []
                
                for target_name, (source_column, agg_func) in agg_dict.items():
                    simple_agg_dict[source_column] = agg_func
                    target_column_names.append(target_name)
                
                # ğŸ”§ é‡è¦ä¿®å¤ï¼šå°†æ—¥æœŸæ—¶é—´è½¬æ¢ä¸ºæ—¥æœŸï¼Œç¡®ä¿æŒ‰æ—¥èšåˆ
                df_for_grouping = df.copy()
                df_for_grouping[date_column] = pd.to_datetime(df_for_grouping[date_column]).dt.date
                
                # æ‰§è¡Œåˆ†ç»„èšåˆï¼ˆæŒ‰æ—¥æœŸèšåˆï¼‰
                grouped = df_for_grouping.groupby(date_column)
                
                # æ‰§è¡Œèšåˆæ“ä½œ
                daily_data = grouped.agg(simple_agg_dict)
                
                # é‡ç½®ç´¢å¼•
                daily_data = daily_data.reset_index()
                
                # é‡å‘½ååˆ—å
                if len(daily_data.columns) == len(target_column_names) + 1:  # +1 for date column
                    new_columns = [date_column] + target_column_names
                    daily_data.columns = new_columns
                
                # å°†æ—¥æœŸåˆ—è½¬æ¢å›datetimeæ ¼å¼ä»¥ä¾¿å›¾è¡¨æ˜¾ç¤º
                daily_data[date_column] = pd.to_datetime(daily_data[date_column])
                
            except Exception as e:
                st.error(f"âŒ pandasèšåˆæ“ä½œå¤±è´¥: {str(e)}")
                return pd.DataFrame()
            
            # æ£€æŸ¥æ—¥æœŸåˆ—æ˜¯å¦å­˜åœ¨
            if date_column not in daily_data.columns:
                st.error(f"âŒ æ—¥æœŸåˆ— '{date_column}' ä¸åœ¨æœ€ç»ˆæ•°æ®ä¸­")
                return pd.DataFrame()
            
            # æŒ‰æ—¥æœŸæ’åº
            daily_data = daily_data.sort_values(date_column)
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœç»Ÿè®¡
            result_summary = []
            for col in daily_data.columns:
                if col != date_column and daily_data[col].dtype in ['int64', 'float64']:
                    total = daily_data[col].sum()
                    avg = daily_data[col].mean()
                    result_summary.append(f"ğŸ“Š {col}ï¼šæ€»è®¡ {total:,}ï¼Œæ—¥å‡ {avg:.1f}")
            
            if result_summary:
                st.info("ğŸ“ˆ **å¤„ç†ç»“æœç»Ÿè®¡**ï¼š\n" + "\n".join(result_summary))
            
            st.success(f"âœ… æ•°æ®èšåˆå®Œæˆï¼šå…± {len(daily_data)} å¤©çš„å…¥åº“æ•°æ®")
            
            return daily_data
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®èšåˆå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def analyze_batch_enhanced(self, df: pd.DataFrame, date_column: str,
                             sku_column: Optional[str] = None,
                             sku_count_column: Optional[str] = None,
                             quantity_column: Optional[str] = None,
                             quantity_count_column: Optional[str] = None,
                             start_date: Optional[datetime] = None,
                             end_date: Optional[datetime] = None) -> Tuple[pd.DataFrame, Dict]:
        """
        å¢å¼ºçš„æ‰¹é‡åˆ†æå…¥åº“æ•°æ®ï¼Œæ”¯æŒåŸå§‹æ•°æ®å’Œèšåˆæ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            date_column: æ—¥æœŸåˆ—å
            sku_column: SKUåˆ—åï¼ˆåŸå§‹ï¼‰
            sku_count_column: SKUæ•°/å¤©åˆ—åï¼ˆèšåˆï¼‰
            quantity_column: ä»¶æ•°åˆ—åï¼ˆåŸå§‹ï¼‰
            quantity_count_column: ä»¶æ•°/å¤©åˆ—åï¼ˆèšåˆï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            Tuple[pd.DataFrame, Dict]: (èšåˆåçš„æ—¥æœŸæ•°æ®, ç»Ÿè®¡æ‘˜è¦)
        """
        try:
            # 1. æ¸…ç†æ—¥æœŸåˆ—
            df_cleaned = self.clean_date_column(df, date_column)
            
            if df_cleaned.empty:
                return pd.DataFrame(), {}
            
            # 2. æ—¥æœŸè¿‡æ»¤
            if start_date and end_date:
                df_cleaned = self.filter_date_range(df_cleaned, date_column, start_date, end_date)
            
            # 3. æŒ‰æ—¥èšåˆæ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
            daily_data = self.aggregate_daily_data_enhanced(
                df_cleaned, date_column, sku_column, sku_count_column,
                quantity_column, quantity_count_column
            )
            
            if daily_data.empty:
                return pd.DataFrame(), {}
            
            # 4. ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
            summary = self.generate_summary_statistics(daily_data, date_column)
            
            return daily_data, summary
            
        except Exception as e:
            st.error(f"âŒ å…¥åº“åˆ†æå¤±è´¥: {str(e)}")
            return pd.DataFrame(), {} 