# -*- coding: utf-8 -*-
"""
åˆ†æå¼•æ“æ ¸å¿ƒæ¨¡å— - åŒ…å«æ‰€æœ‰åˆ†æç»´åº¦çš„æ‰§è¡Œé€»è¾‘
"""

import pandas as pd
import numpy as np
import streamlit as st
from typing import Dict, List, Any, Tuple, Optional
from core.packing_analysis import PackingAnalyzer
from core.data_cleaning import DataCleaning
from core.abc_analysis import ABCAnalyzer
from core.eiq_analysis import EIQAnalyzer
from core.outbound_analysis import OutboundAnalyzer
from core.inbound_analysis import InboundAnalyzer
from utils import DataUtils, SessionStateManager, ValidationUtils, ProgressUtils
from config import ANALYSIS_DIMENSIONS, PREPROCESSING_DIMENSIONS, ABC_CONFIG, EIQ_CONFIG

class AnalysisEngine:
    """åˆ†æå¼•æ“æ ¸å¿ƒç±»"""
    
    def __init__(self, df: pd.DataFrame):
        """
        åˆå§‹åŒ–åˆ†æå¼•æ“
        
        Args:
            df: è¦åˆ†æçš„æ•°æ®æ¡†
        """
        self.df = df.copy()
        self.original_df = df.copy()
        self.analysis_results = {}
        self.data_cleaning = DataCleaning(df)
        
    def execute_preprocessing_step(self, step: str, config: Dict[str, Any]) -> bool:
        """
        æ‰§è¡Œå•ä¸ªå‰ç½®å¤„ç†æ­¥éª¤
        
        Args:
            step: å‰ç½®å¤„ç†æ­¥éª¤åç§°
            config: é…ç½®å‚æ•°
            
        Returns:
            bool: æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        try:
            if step == "å¼‚å¸¸æ•°æ®æ¸…æ´—":
                return self._execute_data_cleaning_with_config(config)
            elif step == "å®¹å™¨é€‰æ‹©":
                return self._execute_container_selection()
            else:
                st.warning(f"æœªçŸ¥çš„å‰ç½®å¤„ç†æ­¥éª¤: {step}")
                return False
        except Exception as e:
            st.error(f"{step}æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def execute_analysis_dimension(self, dimension: str, config: Dict[str, Any]) -> bool:
        """
        æ‰§è¡Œåˆ†æç»´åº¦
        
        Args:
            dimension: åˆ†æç»´åº¦åç§°
            config: é…ç½®å‚æ•°
            
        Returns:
            bool: æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
        """
        try:
            if dimension == "è£…ç®±åˆ†æ":
                return self._execute_packing_analysis(config)
            elif dimension == "ABCåˆ†æ":
                return self._execute_abc_analysis(config)
            elif dimension == "å‡ºåº“åˆ†æ":
                return self._execute_outbound_analysis(config)
            elif dimension == "å…¥åº“åˆ†æ":
                return self._execute_inbound_analysis(config)
            elif dimension == "å®¹å™¨å¯¹æ¯”åˆ†æ":
                return self._execute_container_comparison(config)
            elif dimension == "SKUä»¶æ•°åˆ†æ":
                return self._execute_sku_quantity_analysis(config)
            elif dimension == "å…¥åº“ç®±æ•°åˆ†æ":
                return self._execute_inbound_box_analysis(config)
            elif dimension == "è®¢å•ç»“æ„åˆ†æ":
                return self._execute_order_structure_analysis(config)
            elif dimension == "å•ä»¶å¤šä»¶åˆ†æ":
                return self._execute_single_multi_analysis(config)
            elif dimension == "å‘½ä¸­ç‡åˆ†æ":
                return self._execute_hit_rate_analysis(config)
            else:
                st.warning(f"æœªçŸ¥çš„åˆ†æç»´åº¦: {dimension}")
                return False
                
        except Exception as e:
            st.error(f"{dimension}æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _execute_data_cleaning_with_config(self, config: Dict[str, Any]) -> bool:
        """æ ¹æ®é…ç½®æ‰§è¡Œé«˜çº§å¼‚å¸¸æ•°æ®æ¸…æ´—"""
        all_conditions = config.get('all_conditions', [])
        overall_logic = config.get('overall_logic', 'OR')
        
        if not all_conditions or not any(all_conditions):
            st.error("âŒ æœªé…ç½®ä»»ä½•æ¸…æ´—æ¡ä»¶")
            return False
        
        st.write("ğŸ§¹ **æ­£åœ¨æ‰§è¡Œé«˜çº§å¼‚å¸¸æ•°æ®æ¸…æ´—...**")
        st.write(f"ğŸ“‹ æ¡ä»¶ç»„æ•°: {len(all_conditions)}")
        st.write(f"ğŸ”— ç»„é—´é€»è¾‘: {overall_logic}")
        
        with st.spinner("æ¸…æ´—æ•°æ®ä¸­..."):
            try:
                import pandas as pd
                import numpy as np
                
                result_df = self.df.copy()
                group_results = []
                
                # å¤„ç†æ¯ä¸ªæ¡ä»¶ç»„
                for group_id, group_conditions in enumerate(all_conditions, 1):
                    if not group_conditions:
                        continue
                        
                    group_mask = pd.Series([True] * len(self.df), index=self.df.index)
                    
                    # å¤„ç†ç»„å†…çš„æ¯ä¸ªæ¡ä»¶ï¼ˆANDå…³ç³»ï¼‰
                    for condition in group_conditions:
                        columns = condition.get('columns', [])
                        operator = condition.get('operator', '')
                        value = condition.get('value', '')
                        
                        if not columns:
                            continue
                        
                        condition_mask = pd.Series([False] * len(self.df), index=self.df.index)
                        
                        # å¯¹æ¯ä¸ªé€‰æ‹©çš„åˆ—åº”ç”¨æ¡ä»¶
                        for column in columns:
                            if column not in self.df.columns:
                                continue
                            
                            col_data = self.df[column]
                            
                            # æ ¹æ®è¿ç®—ç¬¦æ‰§è¡Œåˆ¤æ–­
                            if operator == ">":
                                mask = pd.to_numeric(col_data, errors='coerce') > float(value)
                            elif operator == ">=":
                                mask = pd.to_numeric(col_data, errors='coerce') >= float(value)
                            elif operator == "<":
                                mask = pd.to_numeric(col_data, errors='coerce') < float(value)
                            elif operator == "<=":
                                mask = pd.to_numeric(col_data, errors='coerce') <= float(value)
                            elif operator == "==":
                                if isinstance(value, (int, float)):
                                    mask = pd.to_numeric(col_data, errors='coerce') == float(value)
                                else:
                                    mask = col_data.astype(str) == str(value)
                            elif operator == "!=":
                                if isinstance(value, (int, float)):
                                    mask = pd.to_numeric(col_data, errors='coerce') != float(value)
                                else:
                                    mask = col_data.astype(str) != str(value)
                            elif operator == "in_range":
                                if isinstance(value, list) and len(value) == 2:
                                    numeric_data = pd.to_numeric(col_data, errors='coerce')
                                    mask = (numeric_data >= float(value[0])) & (numeric_data <= float(value[1]))
                                else:
                                    mask = pd.Series([False] * len(self.df), index=self.df.index)
                            elif operator == "not_in_range":
                                if isinstance(value, list) and len(value) == 2:
                                    numeric_data = pd.to_numeric(col_data, errors='coerce')
                                    mask = (numeric_data < float(value[0])) | (numeric_data > float(value[1]))
                                else:
                                    mask = pd.Series([False] * len(self.df), index=self.df.index)
                            elif operator == "contains":
                                mask = col_data.astype(str).str.contains(str(value), na=False)
                            elif operator == "not_contains":
                                mask = ~col_data.astype(str).str.contains(str(value), na=False)
                            else:
                                mask = pd.Series([False] * len(self.df), index=self.df.index)
                            
                            mask = mask.fillna(False)
                            condition_mask = condition_mask | mask
                        
                        # ç»„å†…æ¡ä»¶ä½¿ç”¨ANDå…³ç³»
                        group_mask = group_mask & condition_mask
                    
                    group_results.append(group_mask)
                
                # ç»„åˆæ‰€æœ‰æ¡ä»¶ç»„çš„ç»“æœ
                if group_results:
                    final_mask = group_results[0]
                    
                    for i in range(1, len(group_results)):
                        if overall_logic == "OR":
                            final_mask = final_mask | group_results[i]
                        else:  # AND
                            final_mask = final_mask & group_results[i]
                else:
                    final_mask = pd.Series([False] * len(self.df), index=self.df.index)
                
                abnormal_data = self.df[final_mask].copy()
                abnormal_count = final_mask.sum()
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                if abnormal_count == 0:
                    st.info("âœ¨ æœªæ£€æµ‹åˆ°ç¬¦åˆæ¡ä»¶çš„å¼‚å¸¸æ•°æ®")
                    return True
                
                st.write(f"ğŸš¨ æ£€æµ‹åˆ° {abnormal_count} æ¡å¼‚å¸¸æ•°æ®")
                
                # æ˜¾ç¤ºå¼‚å¸¸æ•°æ®é¢„è§ˆ
                if abnormal_count > 0:
                    st.write("**å¼‚å¸¸æ•°æ®é¢„è§ˆï¼š**")
                    self._render_abnormal_data_preview(abnormal_data)
                
                # ç›´æ¥åˆ é™¤å¼‚å¸¸æ•°æ®
                result_df = self.df[~final_mask].copy()
                self.df = result_df
                action_text = "åˆ é™¤"
                
                # ä¿å­˜æ¸…æ´—ç»“æœ
                self.analysis_results["å¼‚å¸¸æ•°æ®æ¸…æ´—"] = {
                    "original_count": len(self.original_df),
                    "cleaned_count": len(result_df),
                    "abnormal_count": abnormal_count,
                    "abnormal_data": abnormal_data,
                    "conditions": all_conditions,
                    "overall_logic": overall_logic,
                    "action": action_text
                }
                
                # æ˜¾ç¤ºæ¸…æ´—ç»“æœ
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("åŸå§‹æ•°æ®", f"{len(self.original_df):,}")
                with col2:
                    st.metric("å¤„ç†åæ•°æ®", f"{len(result_df):,}")
                with col3:
                    st.metric("å¼‚å¸¸æ•°æ®", f"{abnormal_count:,}")
                with col4:
                    st.metric("å¤„ç†æ–¹å¼", action_text)
                
                st.success(f"âœ… é«˜çº§å¼‚å¸¸æ•°æ®æ¸…æ´—å®Œæˆï¼{action_text}äº† {abnormal_count} æ¡å¼‚å¸¸æ•°æ®")
                return True
                
            except Exception as e:
                st.error(f"âŒ é«˜çº§æ¸…æ´—æ‰§è¡Œå¤±è´¥: {str(e)}")
                return False
    
    def _render_abnormal_data_preview(self, abnormal_data):
        """æ¸²æŸ“å¼‚å¸¸æ•°æ®é¢„è§ˆï¼Œæ”¯æŒå®Œæ•´æŸ¥çœ‹å’Œä¸‹è½½"""
        abnormal_count = len(abnormal_data)
        
        # æ–°é€»è¾‘ï¼šå¦‚æœæ•°æ®é‡<=100æ¡ï¼Œé»˜è®¤æ˜¾ç¤ºå…¨éƒ¨ï¼›>100æ¡æ—¶æ˜¾ç¤ºé¢„è§ˆ
        if abnormal_count <= 100:
            # æ•°æ®é‡ä¸å¤§ï¼Œé»˜è®¤å±•å¼€æ˜¾ç¤ºå…¨éƒ¨
            st.success(f"âœ… **æ˜¾ç¤ºå…¨éƒ¨ {abnormal_count} æ¡å¼‚å¸¸æ•°æ®**")
            st.dataframe(abnormal_data, use_container_width=True)
        else:
            # æ•°æ®é‡è¾ƒå¤§ï¼ˆ>100æ¡ï¼‰ï¼Œåªæ˜¾ç¤ºé¢„è§ˆ
            st.info(f"ğŸ” **æ£€æµ‹åˆ° {abnormal_count} æ¡å¼‚å¸¸æ•°æ®**")
            st.caption(f"æ•°æ®é‡è¾ƒå¤§ï¼Œæ˜¾ç¤ºå‰10æ¡é¢„è§ˆï¼Œå®Œæ•´æ•°æ®è¯·é€šè¿‡ä¸‹è½½Excelè·å–")
            
            st.write(f"ğŸ“‹ **å¼‚å¸¸æ•°æ®é¢„è§ˆ**ï¼ˆå‰10æ¡ï¼Œå…± {abnormal_count} æ¡ï¼‰:")
            preview_data = abnormal_data.head(10)
            st.dataframe(preview_data, use_container_width=True)
            st.warning(f"ğŸ’¡ æ•°æ®é‡è¾ƒå¤§ï¼ˆ{abnormal_count} æ¡ï¼‰ï¼Œå®Œæ•´æ•°æ®è¯·ç‚¹å‡»ä¸‹æ–¹Excelä¸‹è½½æŒ‰é’®è·å–")
        
        # æ·»åŠ Excelä¸‹è½½æŒ‰é’®
        col1, col2 = st.columns([6, 2])
        with col2:
            # Excelä¸‹è½½
            from io import BytesIO
            excel_buffer = BytesIO()
            
            try:
                with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                    abnormal_data.to_excel(writer, sheet_name='å¼‚å¸¸æ•°æ®', index=False)
                
                excel_buffer.seek(0)
                
                st.download_button(
                    label=f"ğŸ“Š ä¸‹è½½Excel ({abnormal_count}æ¡)",
                    data=excel_buffer.getvalue(),
                    file_name=f"å¼‚å¸¸æ•°æ®_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    help="ä¸‹è½½ä¸ºExcelæ ¼å¼ï¼Œæ”¯æŒæ•°æ®åˆ†æ",
                    use_container_width=True
                )
            except Exception as e:
                st.info("ğŸ“Š Excelæ ¼å¼æš‚ä¸å¯ç”¨")
    
    def _execute_container_selection(self):
        """æ‰§è¡Œå®¹å™¨é€‰æ‹©"""
        # å®¹å™¨ä¿¡æ¯å·²åœ¨UIç»„ä»¶ä¸­å¤„ç†å¹¶ä¿å­˜åˆ°session_state
        container_info = {
            'length': st.session_state.get("container_length", 600),
            'width': st.session_state.get("container_width", 400),
            'height': st.session_state.get("container_height", 300)
        }
        
        self.analysis_results["å®¹å™¨é€‰æ‹©"] = container_info
        st.success(f"âœ… å®¹å™¨æ ‡å‡†åŒ–å®Œæˆï¼é€‰å®šè§„æ ¼: {container_info['length']}Ã—{container_info['width']}Ã—{container_info['height']} mm")
        return True
    
    def _execute_packing_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œè£…ç®±åˆ†æ"""
        st.write("ğŸ“¦ **æ­£åœ¨æ‰§è¡Œè£…ç®±åˆ†æ...**")
        
        # éªŒè¯å¿…éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = [
            config['length_column'], 
            config['width_column'], 
            config['height_column'], 
            config['inventory_column']
        ]
        
        # æ£€æŸ¥é‡é‡åˆ—ï¼ˆå¯é€‰ï¼‰
        weight_column = config.get('weight_column')
        if weight_column:
            required_columns.append(weight_column)
        
        exists, missing = DataUtils.validate_columns_existence(self.df, required_columns)
        if not exists:
            st.error(f"ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing}")
            return False
        
        # åˆ›å»ºå®¹å™¨ä¿¡æ¯
        container_info = {
            'length': config['container_length'],
            'width': config['container_width'], 
            'height': config['container_height'],
            'weight_limit': config.get('container_weight_limit', 30),
            'size': f"{config['container_length']}x{config['container_width']}x{config['container_height']}",
            'volume': config['container_length'] * config['container_width'] * config['container_height']
        }
        
        # åˆ›å»ºè£…ç®±åˆ†æå™¨
        analyzer = PackingAnalyzer(container_info)
        
        # æ•°æ®é¢„å¤„ç† - è®¡ç®—æ€»åº“å­˜
        inventory_data = pd.to_numeric(self.df[config['inventory_column']], errors='coerce')
        total_inventory = int(inventory_data.sum()) if not inventory_data.isna().all() else 0
        
        with st.spinner("åˆ†æè£…ç®±æ•°æ®ä¸­..."):
            # æ‰§è¡Œè£…ç®±åˆ†æ
            packing_results, processed_count = analyzer.analyze_batch(
                self.df,
                config['length_column'],
                config['width_column'], 
                config['height_column'],
                config['inventory_column'],
                config['data_unit'],
                config.get('weight_column'),
                config.get('weight_unit', 'kg')
            )
            
            # ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
            summary_stats = analyzer.generate_summary_statistics(packing_results, total_inventory)
            
            # ä¿å­˜åˆ†æç»“æœ
            self.analysis_results["è£…ç®±åˆ†æ"] = {
                "packing_results": packing_results,
                "summary_stats": summary_stats,
                "container_info": container_info,
                "config": config,
                "processed_count": processed_count
            }
        
        # æ˜¾ç¤ºç»“æœï¼ˆå§”æ‰˜ç»™UIç»„ä»¶ï¼‰
        from components.ui_components import UIComponents
        UIComponents.render_packing_analysis_results(
            analyzer, packing_results, summary_stats, config['data_unit']
        )
        
        st.success("âœ… è£…ç®±åˆ†æå®Œæˆï¼")
        return True
    
    def _execute_abc_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡ŒABCåˆ†æ"""
        import matplotlib.pyplot as plt
        import plotly.express as px
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
        
        st.write("ğŸ“Š **æ­£åœ¨æ‰§è¡ŒABCåˆ†æ...**")
        
        try:
            # è·å–é…ç½®å‚æ•°
            sku_column = config.get('sku_column')
            quantity_column = config.get('quantity_column')
            a_percentage = config.get('a_percentage', 70)
            b_percentage = config.get('b_percentage', 20)
            
            if not sku_column or not quantity_column:
                st.error("âŒ è¯·é…ç½®SKUåˆ—å’Œæ•°é‡åˆ—")
                return False
            
            # åˆ›å»ºABCåˆ†æå™¨
            abc_config = {
                'classification_method': 'quantity',
                'a_percentage': a_percentage,
                'b_percentage': b_percentage,
                'c_percentage': 100 - a_percentage - b_percentage,
                'sort_order': 'desc'
            }
            
            analyzer = ABCAnalyzer(abc_config)
            
            # æ‰§è¡Œåˆ†æ
            with st.spinner("æ­£åœ¨æ‰§è¡ŒABCåˆ†æ..."):
                abc_results, summary_stats = analyzer.analyze_batch(
                    self.df, sku_column, quantity_column
                )
            
            # æ˜¾ç¤ºç»“æœ
            if not abc_results.empty:
                st.success("âœ… ABCåˆ†æå®Œæˆï¼")
                
                # ç›´æ¥æ˜¾ç¤ºå‡ºåº“æ•°é‡åˆ†å¸ƒï¼Œåˆ é™¤é¡¶éƒ¨SKUç»Ÿè®¡æ‘˜è¦
                st.subheader("ğŸ“Š å‡ºåº“æ•°é‡åˆ†å¸ƒ")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Aç±»å‡ºåº“é‡", f"{summary_stats['a_quantity']:.0f}", delta=None)
                    st.caption(f"ğŸ“¦ **Aç±»SKU**: {summary_stats['a_items']} ä¸ª ({summary_stats['a_item_percentage']:.1f}%)")
                    st.caption(f"ğŸ“Š **å‡ºåº“å æ¯”**: {summary_stats['a_percentage']:.1f}%")
                with col2:
                    st.metric("Bç±»å‡ºåº“é‡", f"{summary_stats['b_quantity']:.0f}", delta=None)
                    st.caption(f"ğŸ“¦ **Bç±»SKU**: {summary_stats['b_items']} ä¸ª ({summary_stats['b_item_percentage']:.1f}%)")
                    st.caption(f"ğŸ“Š **å‡ºåº“å æ¯”**: {summary_stats['b_percentage']:.1f}%")
                with col3:
                    st.metric("Cç±»å‡ºåº“é‡", f"{summary_stats['c_quantity']:.0f}", delta=None)
                    st.caption(f"ğŸ“¦ **Cç±»SKU**: {summary_stats['c_items']} ä¸ª ({summary_stats['c_item_percentage']:.1f}%)")
                    st.caption(f"ğŸ“Š **å‡ºåº“å æ¯”**: {summary_stats['c_percentage']:.1f}%")
                
                # Aç±»å“Top10
                st.subheader("ğŸ† Aç±»å“Top10")
                a_top10 = abc_results[abc_results['ABCåˆ†ç±»'] == 'A'].head(10)
                if not a_top10.empty:
                    st.dataframe(a_top10, use_container_width=True)
                else:
                    st.info("æ²¡æœ‰Aç±»å“æ•°æ®")
                
                # éšè—åˆ†æè¿‡ç¨‹è¡¨æ ¼ï¼Œåªåœ¨ä¸‹è½½ä¸­æä¾›
                # è¿‡ç¨‹è¡¨æ ¼å·²ç§»è‡³ä¸‹è½½åŒºåŸŸ
                
                # ç´¯è®¡æ¯”ä¾‹æ›²çº¿å›¾
                st.subheader("ğŸ“ˆ ABCç´¯è®¡æ¯”ä¾‹æ›²çº¿å›¾")
                self._render_abc_curve_chart(abc_results, a_percentage, a_percentage + b_percentage)
                
                # æ•°æ®å¯¼å‡ºæŒ‰é’®
                st.subheader("ğŸ’¾ æ•°æ®å¯¼å‡º")
                col1, col2 = st.columns(2)
                with col1:
                    csv_data = abc_results.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“„ å¯¼å‡ºè¯¦ç»†åˆ†ææ•°æ®(CSV)",
                        data=csv_data,
                        file_name=f"ABCåˆ†æè¿‡ç¨‹è¡¨æ ¼_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        help="åŒ…å«å®Œæ•´çš„ABCåˆ†æè¿‡ç¨‹è¡¨æ ¼æ•°æ®"
                    )
                
                with col2:
                    # åˆ›å»ºæ‘˜è¦æ•°æ®
                    summary_df = pd.DataFrame([
                        ['Aç±»', summary_stats['a_items'], summary_stats['a_quantity'], summary_stats['a_percentage']],
                        ['Bç±»', summary_stats['b_items'], summary_stats['b_quantity'], summary_stats['b_percentage']],
                        ['Cç±»', summary_stats['c_items'], summary_stats['c_quantity'], summary_stats['c_percentage']]
                    ], columns=['åˆ†ç±»', 'SKUæ•°é‡', 'å‡ºåº“æ•°é‡', 'æ•°é‡å æ¯”(%)'])
                    
                    summary_csv = summary_df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“Š å¯¼å‡ºæ‘˜è¦æ•°æ®(CSV)",
                        data=summary_csv,
                        file_name=f"ABCåˆ†ææ‘˜è¦_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                # ä¿å­˜ç»“æœ
                self.analysis_results["ABCåˆ†æ"] = {
                    "abc_results": abc_results,
                    "summary_stats": summary_stats,
                    "suggestions": []
                }
                
                return True
            else:
                st.warning("âš ï¸ ABCåˆ†ææœªäº§ç”Ÿæœ‰æ•ˆç»“æœ")
                return False
                
        except Exception as e:
            st.error(f"âŒ ABCåˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _render_abc_curve_chart(self, abc_results: pd.DataFrame, a_threshold: float, b_threshold: float):
        """æ¸²æŸ“ABCç´¯è®¡æ¯”ä¾‹æ›²çº¿å›¾"""
        try:
            import plotly.graph_objects as go
            
            # åˆ›å»ºå›¾è¡¨
            fig = go.Figure()
            
            # è®¡ç®—ç´¯è®¡æ¯”ä¾‹æ•°æ®
            x_data = list(range(1, len(abc_results) + 1))
            cumulative_ratio = abc_results['ç´¯è®¡å æ¯”(%)'].tolist()
            
            # è®¡ç®—å„ç±»åˆ«ç»Ÿè®¡æ•°æ®
            a_count = len(abc_results[abc_results['ABCåˆ†ç±»'] == 'A'])
            b_count = len(abc_results[abc_results['ABCåˆ†ç±»'] == 'B'])
            c_count = len(abc_results[abc_results['ABCåˆ†ç±»'] == 'C'])
            total_sku_count = len(abc_results)  # æ€»SKUæ•°é‡
            
            # å®‰å…¨çš„æ•°å€¼è½¬æ¢ï¼Œå¤„ç†å¯èƒ½çš„NaNæˆ–éæ•°å€¼ç±»å‹
            try:
                a_qty = float(abc_results[abc_results['ABCåˆ†ç±»'] == 'A']['å‡ºåº“æ•°é‡'].sum()) if a_count > 0 else 0.0
                b_qty = float(abc_results[abc_results['ABCåˆ†ç±»'] == 'B']['å‡ºåº“æ•°é‡'].sum()) if b_count > 0 else 0.0
                c_qty = float(abc_results[abc_results['ABCåˆ†ç±»'] == 'C']['å‡ºåº“æ•°é‡'].sum()) if c_count > 0 else 0.0
                total_qty = a_qty + b_qty + c_qty
                if total_qty == 0:
                    total_qty = 1  # é¿å…é™¤é›¶é”™è¯¯
            except (ValueError, TypeError):
                a_qty = b_qty = c_qty = total_qty = 0.0
            
            # ä¸»ç´¯è®¡æ›²çº¿ - å¸¦å¡«å……é¢ç§¯
            fig.add_trace(go.Scatter(
                x=x_data,
                y=cumulative_ratio,
                mode='lines',
                name='ç´¯è®¡å æ¯”',
                line=dict(color='#00d4ff', width=3),
                fill='tonexty',
                fillcolor='rgba(0, 212, 255, 0.2)',
                hovertemplate='<b>æ’å:</b> %{x}<br><b>ç´¯è®¡å æ¯”:</b> %{y:.2f}%<extra></extra>'
            ))
            
            # Aç±»åŒºåŸŸå¡«å……å’Œæ ‡æ³¨
            a_mask = abc_results['ABCåˆ†ç±»'] == 'A'
            if a_mask.any():
                a_data = abc_results[a_mask]
                a_x = list(range(1, len(a_data) + 1))
                a_y = a_data['ç´¯è®¡å æ¯”(%)'].tolist()
                
                # Aç±»åŒºåŸŸå¡«å……
                fig.add_trace(go.Scatter(
                    x=a_x + [a_x[-1], a_x[0]],
                    y=a_y + [0, 0],
                    fill='toself',
                    fillcolor='rgba(255, 165, 0, 0.3)',
                    line=dict(color='orange', width=4),
                    name='Aç±»',
                    mode='lines',
                    showlegend=True,
                    hovertemplate='<b>Aç±»SKUæ’å:</b> %{x}<br><b>ç´¯è®¡å æ¯”:</b> %{y:.2f}%<extra></extra>'
                ))
                
                # Aç±»æ³¨é‡Š
                fig.add_annotation(
                    x=len(a_data)//2,
                    y=a_threshold//2,
                    text=f"<b>Aç±»åŒºåŸŸ</b><br>SKU: {a_count}ä¸ª<br>æ•°é‡: {a_qty:.0f}<br>å æ¯”: {a_count/total_sku_count*100:.1f}%",
                    showarrow=True,
                    arrowhead=2,
                    arrowcolor="orange",
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="orange",
                    borderwidth=2,
                    font=dict(size=10, color="black")
                )
            
            # Bç±»åŒºåŸŸå¡«å……å’Œæ ‡æ³¨
            b_mask = abc_results['ABCåˆ†ç±»'] == 'B'
            if b_mask.any():
                b_start = a_count + 1
                b_end = a_count + b_count
                b_x = list(range(b_start, b_end + 1))
                b_data = abc_results[b_mask]
                b_y = b_data['ç´¯è®¡å æ¯”(%)'].tolist()
                
                # Bç±»åŒºåŸŸå¡«å……
                fig.add_trace(go.Scatter(
                    x=b_x + [b_x[-1], b_x[0]],
                    y=b_y + [a_threshold, a_threshold],
                    fill='toself',
                    fillcolor='rgba(128, 128, 128, 0.3)',
                    line=dict(color='gray', width=4),
                    name='Bç±»',
                    mode='lines',
                    showlegend=True,
                    hovertemplate='<b>Bç±»SKUæ’å:</b> %{x}<br><b>ç´¯è®¡å æ¯”:</b> %{y:.2f}%<extra></extra>'
                ))
                
                # Bç±»æ³¨é‡Š
                fig.add_annotation(
                    x=b_start + b_count//2,
                    y=(a_threshold + b_threshold)//2,
                    text=f"<b>Bç±»åŒºåŸŸ</b><br>SKU: {b_count}ä¸ª<br>æ•°é‡: {b_qty:.0f}<br>å æ¯”: {b_count/total_sku_count*100:.1f}%",
                    showarrow=True,
                    arrowhead=2,
                    arrowcolor="gray",
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="gray",
                    borderwidth=2,
                    font=dict(size=10, color="black")
                )
            
            # Cç±»åŒºåŸŸå¡«å……å’Œæ ‡æ³¨
            c_mask = abc_results['ABCåˆ†ç±»'] == 'C'
            if c_mask.any():
                c_start = a_count + b_count + 1
                c_x = list(range(c_start, len(abc_results) + 1))
                c_data = abc_results[c_mask]
                c_y = c_data['ç´¯è®¡å æ¯”(%)'].tolist()
                
                # Cç±»åŒºåŸŸå¡«å……
                fig.add_trace(go.Scatter(
                    x=c_x + [c_x[-1], c_x[0]],
                    y=c_y + [b_threshold, b_threshold],
                    fill='toself',
                    fillcolor='rgba(255, 215, 0, 0.3)',
                    line=dict(color='gold', width=4),
                    name='Cç±»',
                    mode='lines',
                    showlegend=True,
                    hovertemplate='<b>Cç±»SKUæ’å:</b> %{x}<br><b>ç´¯è®¡å æ¯”:</b> %{y:.2f}%<extra></extra>'
                ))
                
                # Cç±»æ³¨é‡Š
                fig.add_annotation(
                    x=c_start + c_count//2,
                    y=(b_threshold + 100)//2,
                    text=f"<b>Cç±»åŒºåŸŸ</b><br>SKU: {c_count}ä¸ª<br>æ•°é‡: {c_qty:.0f}<br>å æ¯”: {c_count/total_sku_count*100:.1f}%",
                    showarrow=True,
                    arrowhead=2,
                    arrowcolor="gold",
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="gold",
                    borderwidth=2,
                    font=dict(size=10, color="black")
                )
            
            # Aç±»å’ŒBç±»é˜ˆå€¼çº¿
            fig.add_hline(
                y=a_threshold,
                line_dash="dash",
                line_color="orange",
                annotation_text=f"Aç±»é˜ˆå€¼ ({a_threshold}%)",
                annotation_position="top right"
            )
            
            fig.add_hline(
                y=b_threshold,
                line_dash="dash", 
                line_color="gray",
                annotation_text=f"Bç±»é˜ˆå€¼ ({b_threshold}%)",
                annotation_position="top right"
            )
            
            # å›¾è¡¨æ ·å¼ - æ·±è‰²ä¸»é¢˜
            fig.update_layout(
                title=dict(
                    text="<b>ABCåˆ†æ - å‡ºåº“æ•°é‡ç´¯è®¡å æ¯”æ›²çº¿</b>",
                    x=0.5,
                    font=dict(size=18, color='white')
                ),
                xaxis=dict(
                    title="<b>SKUæ’å</b>",
                    title_font=dict(size=14, color='white'),
                    showgrid=True,
                    gridcolor='rgba(128,128,128,0.3)',
                    tickfont=dict(color='white')
                ),
                yaxis=dict(
                    title="<b>ç´¯è®¡å æ¯” (%)</b>",
                    title_font=dict(size=14, color='white'),
                    tickfont=dict(color='white'),
                    showgrid=True,
                    gridcolor='rgba(128,128,128,0.3)',
                    range=[0, 100]
                ),
                legend=dict(
                    orientation="h",
                    yanchor="bottom",
                    y=1.02,
                    xanchor="right",
                    x=1,
                    font=dict(color='white')
                ),
                hovermode='x unified',
                plot_bgcolor='rgba(17, 17, 17, 0.8)',  # æ·±è‰²èƒŒæ™¯
                paper_bgcolor='rgba(17, 17, 17, 0.8)',  # çº¸å¼ èƒŒæ™¯ä¹Ÿè®¾ä¸ºæ·±è‰²
                font=dict(color='white'),  # å…¨å±€å­—ä½“é¢œè‰²
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {str(e)}")
            # é™çº§åˆ°è¡¨æ ¼å±•ç¤º
            st.dataframe(abc_results[['æ’å', 'SKU', 'ç´¯è®¡å æ¯”(%)', 'ABCåˆ†ç±»']], use_container_width=True)
    
    def _execute_outbound_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå‡ºåº“é€šç”¨åˆ†æ"""
        try:
            st.subheader("ğŸ“ˆ å‡ºåº“æ•°æ®è¶‹åŠ¿åˆ†æ")
            
            # è·å–é…ç½®å‚æ•°
            date_column = config.get("å‡ºåº“åˆ†æ_date_column")
            
            # æ–°çš„é…ç½®æ ¼å¼ï¼šè®¢å•ç›¸å…³
            order_id_column = config.get("å‡ºåº“åˆ†æ_order_id_column")
            order_count_column = config.get("å‡ºåº“åˆ†æ_order_count_column")
            
            # æ–°çš„é…ç½®æ ¼å¼ï¼šSKUç›¸å…³
            sku_column = config.get("å‡ºåº“åˆ†æ_sku_column")
            sku_count_column = config.get("å‡ºåº“åˆ†æ_sku_count_column")
            
            # æ–°çš„é…ç½®æ ¼å¼ï¼šä»¶æ•°ç›¸å…³
            item_column = config.get("å‡ºåº“åˆ†æ_item_column")
            item_count_column = config.get("å‡ºåº“åˆ†æ_item_count_column")
            
            # æ—¥æœŸèŒƒå›´
            start_date = config.get("å‡ºåº“åˆ†æ_start_date")
            end_date = config.get("å‡ºåº“åˆ†æ_end_date")
            
            # å¤„ç†"æ— æ•°æ®"é€‰é¡¹
            if order_id_column == "æ— æ•°æ®":
                order_id_column = None
            if order_count_column == "æ— æ•°æ®":
                order_count_column = None
            if sku_column == "æ— æ•°æ®":
                sku_column = None
            if sku_count_column == "æ— æ•°æ®":
                sku_count_column = None
            if item_column == "æ— æ•°æ®":
                item_column = None
            if item_count_column == "æ— æ•°æ®":
                item_count_column = None
                
            # éªŒè¯å¿…éœ€é…ç½®
            if not date_column:
                st.error("âŒ è¯·é€‰æ‹©æ—¥æœŸåˆ—")
                return False
                
            # åˆ›å»ºåˆ†æå™¨
            analyzer = OutboundAnalyzer(config)
            
            # æ‰§è¡Œåˆ†æ - ä½¿ç”¨æ–°çš„å‚æ•°æ ¼å¼
            daily_data, summary = analyzer.analyze_batch_enhanced(
                df=self.df,
                date_column=date_column,
                order_id_column=order_id_column,
                order_count_column=order_count_column,
                sku_column=sku_column,
                sku_count_column=sku_count_column,
                item_column=item_column,
                item_count_column=item_count_column,
                start_date=start_date,
                end_date=end_date
            )
            
            if daily_data.empty:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å‡ºåº“æ•°æ®")
                return False
            
            # æ¸²æŸ“è¶‹åŠ¿å›¾è¡¨
            analyzer.render_trend_chart(daily_data, date_column, summary)
            
            # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
            if summary:
                st.subheader("ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
                date_info = summary.get('date_range', {})
                st.info(f"ğŸ“… åˆ†ææ—¶é—´èŒƒå›´ï¼š{date_info.get('start_date')} è‡³ {date_info.get('end_date')}ï¼Œå…± {date_info.get('total_days', 0)} å¤©")
                
                # æ˜¾ç¤ºå„ç»´åº¦ç»Ÿè®¡
                for col, stats in summary.items():
                    if isinstance(stats, dict) and 'total' in stats:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(f"æ€»{col.replace('æ—¥å‡º', '')}", f"{stats['total']:,}")
                        with col2:
                            st.metric(f"æ—¥å‡{col.replace('æ—¥å‡º', '')}", f"{stats['daily_avg']:.1f}")
                        with col3:
                            # æ˜¾ç¤ºæœ€é«˜å’Œæœ€ä½ä¿¡æ¯ï¼ˆåˆ é™¤ç»¿è‰²ç®­å¤´ï¼‰
                            max_val = stats.get('daily_max', 0)
                            min_val = stats.get('daily_min', 0)
                            max_date = stats.get('max_date', '')
                            min_date = stats.get('min_date', '')
                            
                            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
                            max_date_str = max_date.strftime('%Y-%m-%d') if hasattr(max_date, 'strftime') else str(max_date)
                            min_date_str = min_date.strftime('%Y-%m-%d') if hasattr(min_date, 'strftime') else str(min_date)
                            
                            st.metric(
                                "æœ€é«˜/æœ€ä½", 
                                f"{max_val:.0f} / {min_val:.0f}",
                                help=f"æœ€é«˜å€¼: {max_val:.0f} ({max_date_str})\næœ€ä½å€¼: {min_val:.0f} ({min_date_str})"
                            )
                
                # æ·»åŠ EIQåˆ†ææ¯”å€¼ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿçš„ç»´åº¦æ•°æ®ï¼‰
                self._add_eiq_ratios_to_summary(summary)
            
            # æä¾›æ•°æ®ä¸‹è½½
            st.subheader("ğŸ“¥ æ•°æ®å¯¼å‡º")
            csv_data = daily_data.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“„ å¯¼å‡ºå‡ºåº“è¶‹åŠ¿æ•°æ®(CSV)",
                data=csv_data,
                file_name=f"å‡ºåº“è¶‹åŠ¿åˆ†æ_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                help="ä¸‹è½½å®Œæ•´çš„å‡ºåº“è¶‹åŠ¿åˆ†ææ•°æ®"
            )
            
            # ä¿å­˜åˆ†æç»“æœä¾›å…¶ä»–åˆ†æä½¿ç”¨
            self.analysis_results["å‡ºåº“åˆ†æ"] = {
                "daily_data": daily_data,
                "summary": summary,
                "suggestions": []  # ä¸å†ç”Ÿæˆå»ºè®®
            }
            
            return True
            
        except Exception as e:
            st.error(f"âŒ å‡ºåº“åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def _add_eiq_ratios_to_summary(self, summary: Dict[str, Any]) -> None:
        """å°†EIQåˆ†ææ¯”å€¼æ·»åŠ åˆ°å‡ºåº“åˆ†æç»Ÿè®¡æ‘˜è¦ä¸­"""
        try:
            # åˆ†æå¯ç”¨çš„æ•°æ®ç»´åº¦
            available_dimensions = []
            dimension_data = {}
            
            # æ£€æŸ¥è®¢å•æ•°æ®
            if "è®¢å•æ•°/å¤©" in summary:
                available_dimensions.append("è®¢å•")
                dimension_data["è®¢å•"] = summary["è®¢å•æ•°/å¤©"]
                
            # æ£€æŸ¥SKUæ•°æ®  
            if "SKUæ•°/å¤©" in summary:
                available_dimensions.append("SKU")
                dimension_data["SKU"] = summary["SKUæ•°/å¤©"]
                
            # æ£€æŸ¥ä»¶æ•°æ•°æ®
            if "ä»¶æ•°/å¤©" in summary:
                available_dimensions.append("ä»¶æ•°")
                dimension_data["ä»¶æ•°"] = summary["ä»¶æ•°/å¤©"]
            
            if len(available_dimensions) < 2:
                return
            
            # è®¡ç®—EIQæ¯”å€¼
            eiq_ratios = {}
            
            # è¡Œå•æ¯” = SKUæ•°/å¤© Ã· è®¢å•æ•°/å¤©
            if "è®¢å•" in available_dimensions and "SKU" in available_dimensions:
                order_avg = float(dimension_data["è®¢å•"]["daily_avg_no_outliers"])
                sku_avg = float(dimension_data["SKU"]["daily_avg_no_outliers"])
                
                if order_avg > 0:
                    ratio = sku_avg / order_avg
                    eiq_ratios["è¡Œå•æ¯”"] = {
                        "ratio": ratio,
                        "description": "å¹³å‡æ¯ä¸ªè®¢å•åŒ…å«çš„SKUæ•°é‡",
                        "interpretation": self._interpret_ratio("è¡Œå•æ¯”", ratio)
                    }
            
            # ä»¶è¡Œæ¯” = ä»¶æ•°/å¤© Ã· SKUæ•°/å¤©  
            if "ä»¶æ•°" in available_dimensions and "SKU" in available_dimensions:
                item_avg = float(dimension_data["ä»¶æ•°"]["daily_avg_no_outliers"])
                sku_avg = float(dimension_data["SKU"]["daily_avg_no_outliers"])
                
                if sku_avg > 0:
                    ratio = item_avg / sku_avg
                    eiq_ratios["ä»¶è¡Œæ¯”"] = {
                        "ratio": ratio,
                        "description": "å¹³å‡æ¯ä¸ªSKUçš„å‡ºåº“ä»¶æ•°",
                        "interpretation": self._interpret_ratio("ä»¶è¡Œæ¯”", ratio)
                    }
            
            # ä»¶å•æ¯” = ä»¶æ•°/å¤© Ã· è®¢å•æ•°/å¤©
            if "ä»¶æ•°" in available_dimensions and "è®¢å•" in available_dimensions:
                item_avg = float(dimension_data["ä»¶æ•°"]["daily_avg_no_outliers"])
                order_avg = float(dimension_data["è®¢å•"]["daily_avg_no_outliers"])
                
                if order_avg > 0:
                    ratio = item_avg / order_avg
                    eiq_ratios["ä»¶å•æ¯”"] = {
                        "ratio": ratio,
                        "description": "å¹³å‡æ¯ä¸ªè®¢å•çš„ä»¶æ•°",
                        "interpretation": self._interpret_ratio("ä»¶å•æ¯”", ratio)
                    }
            
            # æ˜¾ç¤ºEIQæ¯”å€¼
            if eiq_ratios:
                st.markdown("---")
                st.subheader("ğŸ“Š EIQåˆ†ææ¯”å€¼")
                
                # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºæ¯”å€¼
                ratio_cols = st.columns(len(eiq_ratios))
                for i, (ratio_name, ratio_data) in enumerate(eiq_ratios.items()):
                    with ratio_cols[i]:
                        st.metric(
                            label=ratio_name,
                            value=f"{ratio_data['ratio']:.2f}",
                            help=f"{ratio_data['description']}\n{ratio_data['interpretation']}"
                        )
                        
        except Exception as e:
            st.warning(f"âš ï¸ EIQæ¯”å€¼è®¡ç®—å¤±è´¥: {str(e)}")
    
    def _interpret_ratio(self, ratio_type: str, ratio_value: float) -> str:
        """è§£é‡Šæ¯”å€¼ç»“æœ"""
        if ratio_type == "è¡Œå•æ¯”":
            if ratio_value < 1.5:
                return "è®¢å•ç›¸å¯¹ç®€å•ï¼Œå¤šä¸ºå•å“æˆ–å°‘å“ç§è®¢å•"
            elif ratio_value < 3.0:
                return "è®¢å•å¤æ‚åº¦é€‚ä¸­ï¼Œå¹³å‡åŒ…å«2-3ä¸ªSKU"
            else:
                return "è®¢å•è¾ƒä¸ºå¤æ‚ï¼ŒåŒ…å«å¤šä¸ªSKUå“ç§"
                
        elif ratio_type == "ä»¶è¡Œæ¯”":
            if ratio_value < 2.0:
                return "SKUå‡ºåº“é‡è¾ƒå°ï¼Œå¤šä¸ºå•ä»¶æˆ–å°‘é‡å‡ºåº“"
            elif ratio_value < 5.0:
                return "SKUå‡ºåº“é‡é€‚ä¸­ï¼Œå¹³å‡æ¯ä¸ªSKUå‡ºåº“2-5ä»¶"
            else:
                return "SKUå‡ºåº“é‡è¾ƒå¤§ï¼Œå­˜åœ¨æ‰¹é‡å‡ºåº“æƒ…å†µ"
                
        elif ratio_type == "ä»¶å•æ¯”":
            if ratio_value < 3.0:
                return "è®¢å•ä»¶æ•°è¾ƒå°‘ï¼Œå¤šä¸ºå°æ‰¹é‡è®¢å•"
            elif ratio_value < 10.0:
                return "è®¢å•ä»¶æ•°é€‚ä¸­ï¼Œå¹³å‡æ¯å•3-10ä»¶"
            else:
                return "è®¢å•ä»¶æ•°è¾ƒå¤šï¼Œå­˜åœ¨å¤§æ‰¹é‡è®¢å•"
        
        return f"æ¯”å€¼ä¸º {ratio_value:.2f}"
    
    def _execute_container_comparison(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå®¹å™¨å¯¹æ¯”åˆ†æ"""
        st.write("ğŸ” **æ­£åœ¨æ‰§è¡Œå®¹å™¨å¯¹æ¯”åˆ†æ...**")
        st.info("ğŸ” å®¹å™¨å¯¹æ¯”åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_sku_quantity_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡ŒSKUä»¶æ•°åˆ†æ"""
        st.write("ğŸ”¢ **æ­£åœ¨æ‰§è¡ŒSKUä»¶æ•°åˆ†æ...**")
        st.info("ğŸ”¢ SKUä»¶æ•°åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_inbound_box_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå…¥åº“ç®±æ•°åˆ†æ"""
        st.write("ğŸ“¥ **æ­£åœ¨æ‰§è¡Œå…¥åº“ç®±æ•°åˆ†æ...**")
        st.info("ğŸ“¥ å…¥åº“ç®±æ•°åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_order_structure_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œè®¢å•ç»“æ„åˆ†æ"""
        st.write("ğŸ“‹ **æ­£åœ¨æ‰§è¡Œè®¢å•ç»“æ„åˆ†æ...**")
        st.info("ğŸ“‹ è®¢å•ç»“æ„åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_single_multi_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå•ä»¶å¤šä»¶åˆ†æ"""
        st.write("ğŸ”€ **æ­£åœ¨æ‰§è¡Œå•ä»¶å¤šä»¶åˆ†æ...**")
        st.info("ğŸ”€ å•ä»¶å¤šä»¶åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_hit_rate_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå‘½ä¸­ç‡åˆ†æ"""
        st.write("ğŸ¯ **æ­£åœ¨æ‰§è¡Œå‘½ä¸­ç‡åˆ†æ...**")
        st.info("ğŸ¯ å‘½ä¸­ç‡åˆ†æåŠŸèƒ½å¾…å®Œå–„...")
        return True
    
    def _execute_inbound_analysis(self, config: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå…¥åº“é€šç”¨åˆ†æ"""
        try:
            st.subheader("ğŸ“¥ å…¥åº“æ•°æ®è¶‹åŠ¿åˆ†æ")
            
            # è·å–é…ç½®å‚æ•°
            date_column = config.get("å…¥åº“åˆ†æ_date_column")
            
            # æ–°çš„é…ç½®æ ¼å¼ï¼šSKUç›¸å…³
            sku_column = config.get("å…¥åº“åˆ†æ_sku_column")
            sku_count_column = config.get("å…¥åº“åˆ†æ_sku_count_column")
            
            # æ–°çš„é…ç½®æ ¼å¼ï¼šä»¶æ•°ç›¸å…³
            quantity_column = config.get("å…¥åº“åˆ†æ_quantity_column")
            quantity_count_column = config.get("å…¥åº“åˆ†æ_quantity_count_column")
            
            # æ—¥æœŸèŒƒå›´
            start_date = config.get("å…¥åº“åˆ†æ_start_date")
            end_date = config.get("å…¥åº“åˆ†æ_end_date")
            
            # å¤„ç†"æ— æ•°æ®"é€‰é¡¹
            if sku_column == "æ— æ•°æ®":
                sku_column = None
            if sku_count_column == "æ— æ•°æ®":
                sku_count_column = None
            if quantity_column == "æ— æ•°æ®":
                quantity_column = None
            if quantity_count_column == "æ— æ•°æ®":
                quantity_count_column = None
                
            # éªŒè¯å¿…éœ€é…ç½®
            if not date_column:
                st.error("âŒ è¯·é€‰æ‹©æ—¥æœŸåˆ—")
                return False
                
            # åˆ›å»ºåˆ†æå™¨
            analyzer = InboundAnalyzer(config)
            
            # æ‰§è¡Œå¢å¼ºåˆ†æï¼ˆæ”¯æŒåŸå§‹å’Œèšåˆæ•°æ®ï¼‰
            daily_data, summary = analyzer.analyze_batch_enhanced(
                df=self.df,
                date_column=date_column,
                sku_column=sku_column,
                sku_count_column=sku_count_column,
                quantity_column=quantity_column,
                quantity_count_column=quantity_count_column,
                start_date=start_date,
                end_date=end_date
            )
            
            if daily_data.empty:
                st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å…¥åº“æ•°æ®")
                return False
            
            # æ¸²æŸ“è¶‹åŠ¿å›¾è¡¨
            analyzer.render_trend_chart(daily_data, date_column, summary)
            
            # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
            if summary:
                st.subheader("ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
                date_info = summary.get('date_range', {})
                st.info(f"ğŸ“… åˆ†ææ—¶é—´èŒƒå›´ï¼š{date_info.get('start_date')} è‡³ {date_info.get('end_date')}ï¼Œå…± {date_info.get('total_days', 0)} å¤©")
                
                # æ˜¾ç¤ºå„ç»´åº¦ç»Ÿè®¡
                for col, stats in summary.items():
                    if isinstance(stats, dict) and 'total' in stats:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric(f"æ€»{col.replace('æ—¥å…¥', '')}", f"{stats['total']:,}")
                        with col2:
                            st.metric(f"æ—¥å‡{col.replace('æ—¥å…¥', '')}", f"{stats['daily_avg']:.1f}")
                        with col3:
                            # æ˜¾ç¤ºæœ€é«˜å’Œæœ€ä½ä¿¡æ¯
                            max_val = stats.get('daily_max', 0)
                            min_val = stats.get('daily_min', 0)
                            max_date = stats.get('max_date', '')
                            min_date = stats.get('min_date', '')
                            
                            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
                            max_date_str = max_date.strftime('%Y-%m-%d') if hasattr(max_date, 'strftime') else str(max_date)
                            min_date_str = min_date.strftime('%Y-%m-%d') if hasattr(min_date, 'strftime') else str(min_date)
                            
                            st.metric(
                                "æœ€é«˜/æœ€ä½", 
                                f"{max_val:.0f} / {min_val:.0f}",
                                help=f"æœ€é«˜å€¼: {max_val:.0f} ({max_date_str})\næœ€ä½å€¼: {min_val:.0f} ({min_date_str})"
                            )
            
            # æä¾›æ•°æ®ä¸‹è½½
            st.subheader("ğŸ“¥ æ•°æ®å¯¼å‡º")
            csv_data = daily_data.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“„ å¯¼å‡ºå…¥åº“è¶‹åŠ¿æ•°æ®(CSV)",
                data=csv_data,
                file_name=f"å…¥åº“è¶‹åŠ¿åˆ†æ_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                help="ä¸‹è½½å®Œæ•´çš„å…¥åº“è¶‹åŠ¿åˆ†ææ•°æ®"
            )
            
            # ä¿å­˜åˆ†æç»“æœä¾›å…¶ä»–åˆ†æä½¿ç”¨
            self.analysis_results["å…¥åº“åˆ†æ"] = {
                "daily_data": daily_data,
                "summary": summary,
                "suggestions": []
            }
            
            return True
            
        except Exception as e:
            st.error(f"âŒ å…¥åº“åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            return False
    
    def get_analysis_summary(self) -> Dict[str, Any]:
        """
        è·å–åˆ†ææ‘˜è¦
        
        Returns:
            dict: åˆ†ææ‘˜è¦ä¿¡æ¯
        """
        summary = {
            "total_dimensions": len(self.analysis_results),
            "data_info": {
                "original_rows": len(self.original_df),
                "current_rows": len(self.df),
                "columns": len(self.df.columns)
            },
            "executed_steps": list(self.analysis_results.keys())
        }
        
        return summary
    
    def export_all_results(self) -> Dict[str, pd.DataFrame]:
        """
        å¯¼å‡ºæ‰€æœ‰åˆ†æç»“æœ
        
        Returns:
            dict: åŒ…å«å„ä¸ªåˆ†æç»“æœçš„å­—å…¸
        """
        export_data = {}
        
        for dimension, results in self.analysis_results.items():
            if dimension == "è£…ç®±åˆ†æ":
                # è£…ç®±åˆ†æç»“æœ
                packing_results = results["packing_results"]
                summary_stats = results["summary_stats"]
                
                # åŸºç¡€ç»“æœ
                basic_data = []
                for result in packing_results:
                    basic_data.append({
                        'SKUè¡Œå·': result['SKU_index'] + 1,
                        'è´§ç‰©é•¿åº¦(mm)': result['goods_length_mm'],
                        'è´§ç‰©å®½åº¦(mm)': result['goods_width_mm'],
                        'è´§ç‰©é«˜åº¦(mm)': result['goods_height_mm'],
                        'åº“å­˜ä»¶æ•°': result['inventory_qty'],
                        'æœ€å¤§è£…ç®±æ•°': result['max_per_box'],
                        'éœ€è¦ç®±æ•°': result['boxes_needed'] if result['boxes_needed'] != float('inf') else 'è£…ä¸ä¸‹'
                    })
                
                export_data[f"{dimension}_åŸºç¡€ç»“æœ"] = pd.DataFrame(basic_data)
                
                # ç»Ÿè®¡æ‘˜è¦
                summary_data = {
                    "ç»Ÿè®¡é¡¹ç›®": ["æ€»SKUæ•°", "å¯è£…ç®±SKU", "è£…ä¸ä¸‹SKU", "æ€»åº“å­˜ä»¶æ•°", "æ€»éœ€ç®±å­æ•°", "è£…ç®±æˆåŠŸç‡"],
                    "ç»Ÿè®¡ç»“æœ": [
                        f"{summary_stats['total_sku_count']:,}",
                        f"{summary_stats['can_pack_items']:,}", 
                        f"{summary_stats['cannot_pack_items']:,}",
                        f"{summary_stats['total_inventory']:,}",
                        f"{summary_stats['total_boxes_needed']:.0f}",
                        f"{summary_stats['success_rate']:.1f}%"
                    ]
                }
                export_data[f"{dimension}_ç»Ÿè®¡æ‘˜è¦"] = pd.DataFrame(summary_data)
                
            elif dimension == "æ•°æ®æ¸…æ´—":
                # æ•°æ®æ¸…æ´—ç»“æœ
                cleaning_stats = results["stats"]
                cleaning_data = {
                    "æ¸…æ´—é¡¹ç›®": ["åŸå§‹æ•°æ®é‡", "æ¸…æ´—åæ•°æ®é‡", "ç§»é™¤å¼‚å¸¸æ•°æ®", "æ¸…æ´—ç‡"],
                    "ç»Ÿè®¡ç»“æœ": [
                        f"{results['original_count']:,}",
                        f"{results['cleaned_count']:,}",
                        f"{results['removed_count']:,}",
                        f"{results['cleaning_rate'] * 100:.1f}%"
                    ]
                }
                export_data[f"{dimension}_ç»Ÿè®¡"] = pd.DataFrame(cleaning_data)
                
        return export_data

class DimensionConfigManager:
    """åˆ†æç»´åº¦é…ç½®ç®¡ç†å™¨"""
    
    @staticmethod
    def get_config_requirements(dimension: str) -> List[str]:
        """
        è·å–åˆ†æç»´åº¦çš„é…ç½®è¦æ±‚
        
        Args:
            dimension: åˆ†æç»´åº¦åç§°
            
        Returns:
            list: é…ç½®è¦æ±‚åˆ—è¡¨
        """
        requirements = {
            "è£…ç®±åˆ†æ": ["length_column", "width_column", "height_column", "inventory_column", "data_unit"],
            "ABCåˆ†æ": ["value_column"],
    
            "å®¹å™¨å¯¹æ¯”åˆ†æ": ["length_column", "width_column", "height_column"],
            "SKUä»¶æ•°åˆ†æ": ["sku_column", "quantity_column"],
            "å…¥åº“ç®±æ•°åˆ†æ": ["date_column", "box_column"],
            "è®¢å•ç»“æ„åˆ†æ": ["order_column", "item_column"],
            "å•ä»¶å¤šä»¶åˆ†æ": ["order_column", "quantity_column"],
            "å‘½ä¸­ç‡åˆ†æ": ["target_column", "actual_column"]
        }
        
        return requirements.get(dimension, [])
    
    @staticmethod
    def validate_config(dimension: str, config: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯åˆ†æç»´åº¦é…ç½®
        
        Args:
            dimension: åˆ†æç»´åº¦åç§°
            config: é…ç½®å­—å…¸
            
        Returns:
            tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        errors = []
        requirements = DimensionConfigManager.get_config_requirements(dimension)
        
        for req in requirements:
            if req not in config or config[req] is None:
                errors.append(f"ç¼ºå°‘å¿…éœ€é…ç½®: {req}")
            elif isinstance(config[req], str) and not config[req].strip():
                errors.append(f"é…ç½®ä¸èƒ½ä¸ºç©º: {req}")
        
        return len(errors) == 0, errors
    
    @staticmethod
    def get_default_config(dimension: str) -> Dict[str, Any]:
        """
        è·å–åˆ†æç»´åº¦çš„é»˜è®¤é…ç½®
        
        Args:
            dimension: åˆ†æç»´åº¦åç§°
            
        Returns:
            dict: é»˜è®¤é…ç½®
        """
        defaults = {
            "è£…ç®±åˆ†æ": {
                "data_unit": "cm",
                "weight_unit": "kg",
                "show_details": True,
                "container_length": 600,
                "container_width": 400,
                "container_height": 300,
                "container_weight_limit": 30,
                "use_dividers": False,
                "selected_dividers": []
            },
            "ABCåˆ†æ": {
                "classification_method": "revenue",
                "a_percentage": 20,
                "b_percentage": 30
            },

            "å®¹å™¨å¯¹æ¯”åˆ†æ": {
                "compare_containers": ["600x400x300", "650x450x350", "700x500x400"]
            }
        }
        
        return defaults.get(dimension, {}) 